{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:48.719232Z",
     "iopub.status.busy": "2020-12-06T13:05:48.719001Z",
     "iopub.status.idle": "2020-12-06T13:05:52.332571Z",
     "shell.execute_reply": "2020-12-06T13:05:52.331998Z",
     "shell.execute_reply.started": "2020-12-06T13:05:48.719187Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert code here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertConfig, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sent_encoder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:52.333663Z",
     "iopub.status.busy": "2020-12-06T13:05:52.333489Z",
     "iopub.status.idle": "2020-12-06T13:05:52.364410Z",
     "shell.execute_reply": "2020-12-06T13:05:52.363744Z",
     "shell.execute_reply.started": "2020-12-06T13:05:52.333642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:52.368883Z",
     "iopub.status.busy": "2020-12-06T13:05:52.368655Z",
     "iopub.status.idle": "2020-12-06T13:05:52.931584Z",
     "shell.execute_reply": "2020-12-06T13:05:52.931035Z",
     "shell.execute_reply.started": "2020-12-06T13:05:52.368852Z"
    }
   },
   "outputs": [],
   "source": [
    "models = ['bert-base-multilingual-cased', 'xlm-roberta-base', 'sagorsarker/bangla-bert-base', 'ai4bharat/indic-bert', '/scratch/indic-tapt/checkpoint-5000/']\n",
    "model_num = 4\n",
    "tokenizer = AutoTokenizer.from_pretrained(models[model_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:52.932671Z",
     "iopub.status.busy": "2020-12-06T13:05:52.932512Z",
     "iopub.status.idle": "2020-12-06T13:05:52.962961Z",
     "shell.execute_reply": "2020-12-06T13:05:52.962494Z",
     "shell.execute_reply.started": "2020-12-06T13:05:52.932651Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('data/valid.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:52.963890Z",
     "iopub.status.busy": "2020-12-06T13:05:52.963734Z",
     "iopub.status.idle": "2020-12-06T13:05:52.975313Z",
     "shell.execute_reply": "2020-12-06T13:05:52.974806Z",
     "shell.execute_reply.started": "2020-12-06T13:05:52.963870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>126</td>\n",
       "      <td>बिहार: समान काम, समान वेतन की मांग को लेकर प्र...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>4977</td>\n",
       "      <td>कोरोना महामारी के कारण देश भर में जनता परेशान ...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>978</td>\n",
       "      <td>लोकसभा ने बनाया इतिहास, पिछले 20 साल में सबसे ...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>2847</td>\n",
       "      <td>#Noida में अब तक 145 पुलिसकर्मी #कोरोना_पॉजिटि...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>5543</td>\n",
       "      <td>कश्मीर की जन्नत को जहन्नम की आग बनाने वालों इस...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>3426</td>\n",
       "      <td>मुसलमानों को ज्ञान देता हुआ एक मुसलमान बुद्धिज...</td>\n",
       "      <td>hate,offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>2148</td>\n",
       "      <td>भाईया भारतीय मुस्लिम भाईयों आप सभी देश के वामप...</td>\n",
       "      <td>offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>278</td>\n",
       "      <td>5 महीने हो गए इन साधु की हत्या हुई .. आज तक को...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>3264</td>\n",
       "      <td>India-China Rift: लद्दाख में BRO ने लगाई नई मश...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>2535</td>\n",
       "      <td>गलती मोदी की नहीं जो देश को धोका दिया, गलती उन...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>3633</td>\n",
       "      <td>Noida Metro: नोएडा में 7 सितंबर से शुरू होगी म...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>3152</td>\n",
       "      <td>अनुच्छेद 370 को हटाने के बाद पाकिस्तान में हाह...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>1326</td>\n",
       "      <td>@anuragkashyap72 साला तेरे माँ बाप कैसे होंगे ...</td>\n",
       "      <td>hate,offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>1780</td>\n",
       "      <td>@ABPNews स्वरा भास्कर देशद्रोही मुदो पर समर्थन...</td>\n",
       "      <td>defamation,fake,offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2512</th>\n",
       "      <td>2628</td>\n",
       "      <td>महाराष्ट्र में घर खरीदना होगा सस्ता, डिस्काउंट...</td>\n",
       "      <td>non-hostile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>5504</td>\n",
       "      <td>आप को पता नहीं चलेगा की कब बैंडेज कूद कर बाएं ...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>153</td>\n",
       "      <td>@narendramodi देश की सरकारी कंपनी बीएसएनएल को ...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1944</th>\n",
       "      <td>2012</td>\n",
       "      <td>दलित मूछें रखें तो कुछ कुत्तों को जलन होती है ...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>4284</td>\n",
       "      <td>फिल्म अभिनेता नसीरुद्दीन शाह बीमार, नसीरुद्दीन...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>1581</td>\n",
       "      <td>नेपाल का प्यारा, चीन का दुलारा, बुद्धि का मारा...</td>\n",
       "      <td>defamation,offensive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unique ID                                               Post  \\\n",
       "125         126  बिहार: समान काम, समान वेतन की मांग को लेकर प्र...   \n",
       "4775       4977  कोरोना महामारी के कारण देश भर में जनता परेशान ...   \n",
       "977         978  लोकसभा ने बनाया इतिहास, पिछले 20 साल में सबसे ...   \n",
       "2731       2847  #Noida में अब तक 145 पुलिसकर्मी #कोरोना_पॉजिटि...   \n",
       "5341       5543  कश्मीर की जन्नत को जहन्नम की आग बनाने वालों इस...   \n",
       "3310       3426  मुसलमानों को ज्ञान देता हुआ एक मुसलमान बुद्धिज...   \n",
       "2080       2148  भाईया भारतीय मुस्लिम भाईयों आप सभी देश के वामप...   \n",
       "277         278  5 महीने हो गए इन साधु की हत्या हुई .. आज तक को...   \n",
       "3148       3264  India-China Rift: लद्दाख में BRO ने लगाई नई मश...   \n",
       "2419       2535  गलती मोदी की नहीं जो देश को धोका दिया, गलती उन...   \n",
       "3517       3633  Noida Metro: नोएडा में 7 सितंबर से शुरू होगी म...   \n",
       "3036       3152  अनुच्छेद 370 को हटाने के बाद पाकिस्तान में हाह...   \n",
       "1258       1326  @anuragkashyap72 साला तेरे माँ बाप कैसे होंगे ...   \n",
       "1712       1780  @ABPNews स्वरा भास्कर देशद्रोही मुदो पर समर्थन...   \n",
       "2512       2628  महाराष्ट्र में घर खरीदना होगा सस्ता, डिस्काउंट...   \n",
       "5302       5504  आप को पता नहीं चलेगा की कब बैंडेज कूद कर बाएं ...   \n",
       "152         153  @narendramodi देश की सरकारी कंपनी बीएसएनएल को ...   \n",
       "1944       2012  दलित मूछें रखें तो कुछ कुत्तों को जलन होती है ...   \n",
       "4168       4284  फिल्म अभिनेता नसीरुद्दीन शाह बीमार, नसीरुद्दीन...   \n",
       "1513       1581  नेपाल का प्यारा, चीन का दुलारा, बुद्धि का मारा...   \n",
       "\n",
       "                     Labels Set  \n",
       "125                 non-hostile  \n",
       "4775                non-hostile  \n",
       "977                 non-hostile  \n",
       "2731                non-hostile  \n",
       "5341                  offensive  \n",
       "3310             hate,offensive  \n",
       "2080                  offensive  \n",
       "277                        hate  \n",
       "3148                non-hostile  \n",
       "2419                       fake  \n",
       "3517                non-hostile  \n",
       "3036                non-hostile  \n",
       "1258             hate,offensive  \n",
       "1712  defamation,fake,offensive  \n",
       "2512                non-hostile  \n",
       "5302                       fake  \n",
       "152                        hate  \n",
       "1944                       hate  \n",
       "4168                       fake  \n",
       "1513       defamation,offensive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:52.976159Z",
     "iopub.status.busy": "2020-12-06T13:05:52.976011Z",
     "iopub.status.idle": "2020-12-06T13:05:52.979483Z",
     "shell.execute_reply": "2020-12-06T13:05:52.979025Z",
     "shell.execute_reply.started": "2020-12-06T13:05:52.976140Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_labels(label):\n",
    "    tmp = label.split(',')\n",
    "    ls = [0, 0, 0, 0]\n",
    "    if tmp[0] == 'non-hostile':\n",
    "        return ls\n",
    "    if 'fake' in tmp:\n",
    "        ls[0] = 1\n",
    "    if 'hate' in tmp:\n",
    "        ls[1] = 1\n",
    "    if 'offensive' in tmp:\n",
    "        ls[2] = 1\n",
    "    if 'defamation' in tmp:\n",
    "        ls[3] = 1\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:52.980322Z",
     "iopub.status.busy": "2020-12-06T13:05:52.980151Z",
     "iopub.status.idle": "2020-12-06T13:05:52.987401Z",
     "shell.execute_reply": "2020-12-06T13:05:52.986920Z",
     "shell.execute_reply.started": "2020-12-06T13:05:52.980303Z"
    }
   },
   "outputs": [],
   "source": [
    "train['encodelabels'] = train['Labels Set'].apply(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:52.989142Z",
     "iopub.status.busy": "2020-12-06T13:05:52.988992Z",
     "iopub.status.idle": "2020-12-06T13:05:53.002694Z",
     "shell.execute_reply": "2020-12-06T13:05:53.002243Z",
     "shell.execute_reply.started": "2020-12-06T13:05:52.989123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique ID</th>\n",
       "      <th>Post</th>\n",
       "      <th>Labels Set</th>\n",
       "      <th>encodelabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>4392</td>\n",
       "      <td>पूर्व राष्ट्रपति #PranabMukherjee के राजनीतिक ...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>3248</td>\n",
       "      <td>RT @Rofl_RavishNDTV: ब्रेकिंग न्यूज़-  कानपुर ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>3947</td>\n",
       "      <td>#Sitapur पेट्रोल पंप पर 2 दबंगों ने की सेल्समै...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>2156</td>\n",
       "      <td>सुने हैं कि करण जौहर गे है... गे का मतलब होता ...</td>\n",
       "      <td>defamation</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3151</td>\n",
       "      <td>@ArvindD68203391 एकदम सही बात बोले आप ये साले ...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>1086</td>\n",
       "      <td>@bewda_anna @Rolf_007 IPL देख रहा होगा कमिना</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5201</td>\n",
       "      <td>रिलायंस रिटेल को मिल सकता है बड़ा निवेश, वॉलमा...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>3396</td>\n",
       "      <td>#SureshRaina के ट्वीट के बाद पंजाब पुलिस का बड...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>5174</td>\n",
       "      <td>Motorola One 5G है कंपनी का किफायती 5जी स्मार्...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4860</th>\n",
       "      <td>5062</td>\n",
       "      <td>ये अवैध मानव अंग तस्करी का धंधा है। जो कोरोना ...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>306</td>\n",
       "      <td>वायरल की गयी फोटो पे लिखा है की राहुल गाँधी के...</td>\n",
       "      <td>fake</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>3240</td>\n",
       "      <td>NEWS18 इंडिया पर EXCLUSIVE बातचीत में संदीप सि...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>3906</td>\n",
       "      <td>@RahulGandhi तेरे जैसे भड़वों को बस किसानों को...</td>\n",
       "      <td>defamation,fake,hate,offensive</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>4011</td>\n",
       "      <td>@Dr_Uditraj @INCIndia जहां उसकी जगह है वहां पह...</td>\n",
       "      <td>defamation</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>2461</td>\n",
       "      <td>भारत एक ऐसा देश बन रहा है जहां कोई भी मुँह उठा...</td>\n",
       "      <td>hate</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>5324</td>\n",
       "      <td>#GhantiBajao में आज रात 10 बजे @anuraagmuskaan...</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>RT @ReshmaHindusta1: रिया जेल गयी इसमें कौन सी...</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>2886</td>\n",
       "      <td>@anuragkashyap72 तू निहायत कमीना इंसान है</td>\n",
       "      <td>offensive</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>3651</td>\n",
       "      <td>1975 इमरजेंसी के बाद  इंदिरा गांधी ने दिल्ली प...</td>\n",
       "      <td>defamation,hate</td>\n",
       "      <td>[0, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>4178</td>\n",
       "      <td>बाराबंकी शराब हादसे के बाद से मोदी जी का अहम फ...</td>\n",
       "      <td>fake</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unique ID                                               Post  \\\n",
       "4276       4392  पूर्व राष्ट्रपति #PranabMukherjee के राजनीतिक ...   \n",
       "3132       3248  RT @Rofl_RavishNDTV: ब्रेकिंग न्यूज़-  कानपुर ...   \n",
       "3831       3947  #Sitapur पेट्रोल पंप पर 2 दबंगों ने की सेल्समै...   \n",
       "2088       2156  सुने हैं कि करण जौहर गे है... गे का मतलब होता ...   \n",
       "3035       3151  @ArvindD68203391 एकदम सही बात बोले आप ये साले ...   \n",
       "1085       1086       @bewda_anna @Rolf_007 IPL देख रहा होगा कमिना   \n",
       "4999       5201  रिलायंस रिटेल को मिल सकता है बड़ा निवेश, वॉलमा...   \n",
       "3280       3396  #SureshRaina के ट्वीट के बाद पंजाब पुलिस का बड...   \n",
       "4972       5174  Motorola One 5G है कंपनी का किफायती 5जी स्मार्...   \n",
       "4860       5062  ये अवैध मानव अंग तस्करी का धंधा है। जो कोरोना ...   \n",
       "305         306  वायरल की गयी फोटो पे लिखा है की राहुल गाँधी के...   \n",
       "3124       3240  NEWS18 इंडिया पर EXCLUSIVE बातचीत में संदीप सि...   \n",
       "3790       3906  @RahulGandhi तेरे जैसे भड़वों को बस किसानों को...   \n",
       "3895       4011  @Dr_Uditraj @INCIndia जहां उसकी जगह है वहां पह...   \n",
       "2345       2461  भारत एक ऐसा देश बन रहा है जहां कोई भी मुँह उठा...   \n",
       "5122       5324  #GhantiBajao में आज रात 10 बजे @anuraagmuskaan...   \n",
       "195         196  RT @ReshmaHindusta1: रिया जेल गयी इसमें कौन सी...   \n",
       "2770       2886          @anuragkashyap72 तू निहायत कमीना इंसान है   \n",
       "3535       3651  1975 इमरजेंसी के बाद  इंदिरा गांधी ने दिल्ली प...   \n",
       "4062       4178  बाराबंकी शराब हादसे के बाद से मोदी जी का अहम फ...   \n",
       "\n",
       "                          Labels Set  encodelabels  \n",
       "4276                     non-hostile  [0, 0, 0, 0]  \n",
       "3132                            hate  [0, 1, 0, 0]  \n",
       "3831                     non-hostile  [0, 0, 0, 0]  \n",
       "2088                      defamation  [0, 0, 0, 1]  \n",
       "3035                            hate  [0, 1, 0, 0]  \n",
       "1085                       offensive  [0, 0, 1, 0]  \n",
       "4999                     non-hostile  [0, 0, 0, 0]  \n",
       "3280                     non-hostile  [0, 0, 0, 0]  \n",
       "4972                     non-hostile  [0, 0, 0, 0]  \n",
       "4860                     non-hostile  [0, 0, 0, 0]  \n",
       "305                             fake  [1, 0, 0, 0]  \n",
       "3124                     non-hostile  [0, 0, 0, 0]  \n",
       "3790  defamation,fake,hate,offensive  [1, 1, 1, 1]  \n",
       "3895                      defamation  [0, 0, 0, 1]  \n",
       "2345                            hate  [0, 1, 0, 0]  \n",
       "5122                     non-hostile  [0, 0, 0, 0]  \n",
       "195                        offensive  [0, 0, 1, 0]  \n",
       "2770                       offensive  [0, 0, 1, 0]  \n",
       "3535                 defamation,hate  [0, 1, 0, 1]  \n",
       "4062                            fake  [1, 0, 0, 0]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:53.003841Z",
     "iopub.status.busy": "2020-12-06T13:05:53.003688Z",
     "iopub.status.idle": "2020-12-06T13:05:53.007581Z",
     "shell.execute_reply": "2020-12-06T13:05:53.007113Z",
     "shell.execute_reply.started": "2020-12-06T13:05:53.003822Z"
    }
   },
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:53.008373Z",
     "iopub.status.busy": "2020-12-06T13:05:53.008229Z",
     "iopub.status.idle": "2020-12-06T13:05:53.012967Z",
     "shell.execute_reply": "2020-12-06T13:05:53.012518Z",
     "shell.execute_reply.started": "2020-12-06T13:05:53.008355Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:53.013780Z",
     "iopub.status.busy": "2020-12-06T13:05:53.013635Z",
     "iopub.status.idle": "2020-12-06T13:05:53.021055Z",
     "shell.execute_reply": "2020-12-06T13:05:53.020603Z",
     "shell.execute_reply.started": "2020-12-06T13:05:53.013762Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Post\n",
    "        self.targets = self.data.encodelabels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:53.021847Z",
     "iopub.status.busy": "2020-12-06T13:05:53.021704Z",
     "iopub.status.idle": "2020-12-06T13:05:53.030651Z",
     "shell.execute_reply": "2020-12-06T13:05:53.030196Z",
     "shell.execute_reply.started": "2020-12-06T13:05:53.021829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (5527, 4)\n",
      "TRAIN Dataset: (4422, 4)\n",
      "TEST Dataset: (1105, 4)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_data=train.sample(frac=train_size,random_state=200)\n",
    "test_data=train.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "training_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:53.031477Z",
     "iopub.status.busy": "2020-12-06T13:05:53.031331Z",
     "iopub.status.idle": "2020-12-06T13:05:53.034440Z",
     "shell.execute_reply": "2020-12-06T13:05:53.033982Z",
     "shell.execute_reply.started": "2020-12-06T13:05:53.031458Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:53.035319Z",
     "iopub.status.busy": "2020-12-06T13:05:53.035132Z",
     "iopub.status.idle": "2020-12-06T13:05:59.116402Z",
     "shell.execute_reply": "2020-12-06T13:05:59.115916Z",
     "shell.execute_reply.started": "2020-12-06T13:05:53.035300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(models[model_num])\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:59.117455Z",
     "iopub.status.busy": "2020-12-06T13:05:59.117300Z",
     "iopub.status.idle": "2020-12-06T13:05:59.120030Z",
     "shell.execute_reply": "2020-12-06T13:05:59.119617Z",
     "shell.execute_reply.started": "2020-12-06T13:05:59.117434Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:59.120820Z",
     "iopub.status.busy": "2020-12-06T13:05:59.120656Z",
     "iopub.status.idle": "2020-12-06T13:05:59.125884Z",
     "shell.execute_reply": "2020-12-06T13:05:59.125473Z",
     "shell.execute_reply.started": "2020-12-06T13:05:59.120801Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:59.126659Z",
     "iopub.status.busy": "2020-12-06T13:05:59.126510Z",
     "iopub.status.idle": "2020-12-06T13:05:59.145282Z",
     "shell.execute_reply": "2020-12-06T13:05:59.144803Z",
     "shell.execute_reply.started": "2020-12-06T13:05:59.126639Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "#         if _%50==0:\n",
    "#             print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    final_outputs = np.array(fin_outputs) >=0.5\n",
    "    final = []\n",
    "    final_t = []\n",
    "    final_fine = [[],[],[],[]]\n",
    "    final_fine_t = [[],[],[],[]]\n",
    "    for (i,j) in zip(final_outputs, fin_targets):\n",
    "        output_sum = sum(i)\n",
    "        target_sum = sum(j)\n",
    "        if output_sum == 0:\n",
    "            final.append(0)\n",
    "        else:\n",
    "            final.append(1)\n",
    "        if target_sum == 0:\n",
    "            final_t.append(0)\n",
    "        else:\n",
    "            final_t.append(1)\n",
    "        for p in range(4):\n",
    "            final_fine[p].append(int(i[p]))\n",
    "            final_fine_t[p].append(int(j[p]))\n",
    "    print(\"Coarse:\")\n",
    "    print(classification_report(final, final_t))\n",
    "    for i in range(4):\n",
    "        print(\"Fine\", i)\n",
    "        print(classification_report(final_fine[i], final_fine_t[i]))\n",
    "#     return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:05:59.146045Z",
     "iopub.status.busy": "2020-12-06T13:05:59.145897Z",
     "iopub.status.idle": "2020-12-06T13:12:21.808204Z",
     "shell.execute_reply": "2020-12-06T13:12:21.807637Z",
     "shell.execute_reply.started": "2020-12-06T13:05:59.146026Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/tathagata.raha/miniconda3/envs/fastai/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1764: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "139it [00:33,  4.09it/s]\n",
      "2it [00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3956594467163086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.64it/s]\n",
      "/home/tathagata.raha/miniconda3/envs/fastai/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.52      0.69      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.52      1105\n",
      "   macro avg       0.50      0.26      0.34      1105\n",
      "weighted avg       1.00      0.52      0.69      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.79      1105\n",
      "   macro avg       0.50      0.40      0.44      1105\n",
      "weighted avg       1.00      0.79      0.88      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.86      0.93      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.87      0.93      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.07it/s]\n",
      "2it [00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.22554443776607513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.49it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.60      0.75       947\n",
      "           1       0.29      0.96      0.44       158\n",
      "\n",
      "    accuracy                           0.65      1105\n",
      "   macro avg       0.64      0.78      0.60      1105\n",
      "weighted avg       0.89      0.65      0.70      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       947\n",
      "           1       0.60      0.88      0.71       158\n",
      "\n",
      "    accuracy                           0.90      1105\n",
      "   macro avg       0.79      0.89      0.83      1105\n",
      "weighted avg       0.92      0.90      0.91      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.86      0.93      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.87      0.93      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.03it/s]\n",
      "2it [00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.08021894097328186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.37it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.78       859\n",
      "           1       0.44      0.95      0.60       246\n",
      "\n",
      "    accuracy                           0.72      1105\n",
      "   macro avg       0.71      0.80      0.69      1105\n",
      "weighted avg       0.86      0.72      0.74      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       859\n",
      "           1       0.81      0.76      0.78       246\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.87      0.85      0.86      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.86      0.93      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.87      0.93      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.00it/s]\n",
      "2it [00:00, 10.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.45036882162094116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.35it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.63      0.77       897\n",
      "           1       0.38      0.96      0.54       208\n",
      "\n",
      "    accuracy                           0.69      1105\n",
      "   macro avg       0.68      0.79      0.65      1105\n",
      "weighted avg       0.87      0.69      0.73      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       897\n",
      "           1       0.74      0.83      0.78       208\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.85      0.88      0.86      1105\n",
      "weighted avg       0.92      0.91      0.92      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.86      0.93      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.87      0.93      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:35,  3.97it/s]\n",
      "2it [00:00, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.04720199853181839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.27it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79       861\n",
      "           1       0.44      0.96      0.61       244\n",
      "\n",
      "    accuracy                           0.72      1105\n",
      "   macro avg       0.71      0.81      0.70      1105\n",
      "weighted avg       0.86      0.72      0.75      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       900\n",
      "           1       0.74      0.83      0.78       205\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.85      0.88      0.86      1105\n",
      "weighted avg       0.92      0.91      0.92      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.50      0.43      0.46      1105\n",
      "weighted avg       1.00      0.86      0.93      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      1066\n",
      "           1       0.16      0.59      0.25        39\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.57      0.74      0.59      1105\n",
      "weighted avg       0.95      0.87      0.91      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:35,  3.96it/s]\n",
      "2it [00:00, 10.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.4644303321838379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.30it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.73      0.83       780\n",
      "           1       0.60      0.97      0.74       325\n",
      "\n",
      "    accuracy                           0.80      1105\n",
      "   macro avg       0.79      0.85      0.79      1105\n",
      "weighted avg       0.87      0.80      0.81      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94       881\n",
      "           1       0.77      0.79      0.78       224\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.86      0.86      0.86      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1070\n",
      "           1       0.14      0.60      0.22        35\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.56      0.74      0.57      1105\n",
      "weighted avg       0.96      0.87      0.90      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1004\n",
      "           1       0.37      0.54      0.44       101\n",
      "\n",
      "    accuracy                           0.88      1105\n",
      "   macro avg       0.66      0.73      0.69      1105\n",
      "weighted avg       0.90      0.88      0.89      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:35,  3.96it/s]\n",
      "2it [00:00, 10.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.2750900983810425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.27it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81       815\n",
      "           1       0.53      0.96      0.68       290\n",
      "\n",
      "    accuracy                           0.76      1105\n",
      "   macro avg       0.75      0.83      0.75      1105\n",
      "weighted avg       0.86      0.76      0.78      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       899\n",
      "           1       0.74      0.83      0.78       206\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.85      0.88      0.86      1105\n",
      "weighted avg       0.92      0.91      0.92      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.92      1059\n",
      "           1       0.15      0.50      0.23        46\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.56      0.69      0.58      1105\n",
      "weighted avg       0.94      0.86      0.89      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      1039\n",
      "           1       0.25      0.56      0.35        66\n",
      "\n",
      "    accuracy                           0.87      1105\n",
      "   macro avg       0.61      0.73      0.64      1105\n",
      "weighted avg       0.93      0.87      0.90      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:35,  3.96it/s]\n",
      "2it [00:00, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.20214912295341492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.28it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.77      0.86       733\n",
      "           1       0.68      0.97      0.80       372\n",
      "\n",
      "    accuracy                           0.83      1105\n",
      "   macro avg       0.83      0.87      0.83      1105\n",
      "weighted avg       0.88      0.83      0.84      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       900\n",
      "           1       0.73      0.82      0.77       205\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.84      0.87      0.86      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       971\n",
      "           1       0.44      0.51      0.47       134\n",
      "\n",
      "    accuracy                           0.86      1105\n",
      "   macro avg       0.69      0.71      0.70      1105\n",
      "weighted avg       0.87      0.86      0.87      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94      1006\n",
      "           1       0.41      0.61      0.49        99\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.68      0.76      0.71      1105\n",
      "weighted avg       0.91      0.89      0.90      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:35,  3.96it/s]\n",
      "2it [00:00, 10.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss:  0.01059902273118496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.03it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       725\n",
      "           1       0.69      0.97      0.81       380\n",
      "\n",
      "    accuracy                           0.84      1105\n",
      "   macro avg       0.84      0.87      0.84      1105\n",
      "weighted avg       0.88      0.84      0.85      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       879\n",
      "           1       0.79      0.81      0.80       226\n",
      "\n",
      "    accuracy                           0.92      1105\n",
      "   macro avg       0.87      0.88      0.87      1105\n",
      "weighted avg       0.92      0.92      0.92      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92      1002\n",
      "           1       0.31      0.47      0.37       103\n",
      "\n",
      "    accuracy                           0.85      1105\n",
      "   macro avg       0.63      0.68      0.65      1105\n",
      "weighted avg       0.88      0.85      0.87      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1006\n",
      "           1       0.39      0.58      0.46        99\n",
      "\n",
      "    accuracy                           0.88      1105\n",
      "   macro avg       0.67      0.74      0.70      1105\n",
      "weighted avg       0.91      0.88      0.89      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:35,  3.95it/s]\n",
      "2it [00:00, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss:  0.11809884011745453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       719\n",
      "           1       0.71      0.97      0.82       386\n",
      "\n",
      "    accuracy                           0.85      1105\n",
      "   macro avg       0.84      0.87      0.84      1105\n",
      "weighted avg       0.88      0.85      0.85      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       911\n",
      "           1       0.71      0.84      0.77       194\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.84      0.88      0.86      1105\n",
      "weighted avg       0.92      0.91      0.91      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       974\n",
      "           1       0.38      0.45      0.41       131\n",
      "\n",
      "    accuracy                           0.85      1105\n",
      "   macro avg       0.65      0.68      0.66      1105\n",
      "weighted avg       0.86      0.85      0.85      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       990\n",
      "           1       0.46      0.58      0.51       115\n",
      "\n",
      "    accuracy                           0.88      1105\n",
      "   macro avg       0.70      0.75      0.72      1105\n",
      "weighted avg       0.90      0.88      0.89      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:12:21.809322Z",
     "iopub.status.busy": "2020-12-06T13:12:21.809165Z",
     "iopub.status.idle": "2020-12-06T13:12:21.813798Z",
     "shell.execute_reply": "2020-12-06T13:12:21.813389Z",
     "shell.execute_reply.started": "2020-12-06T13:12:21.809300Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:12:21.814520Z",
     "iopub.status.busy": "2020-12-06T13:12:21.814378Z",
     "iopub.status.idle": "2020-12-06T13:12:25.204239Z",
     "shell.execute_reply": "2020-12-06T13:12:25.203837Z",
     "shell.execute_reply.started": "2020-12-06T13:12:21.814498Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.35it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs, targets = validation(testing_loader)\n",
    "\n",
    "final_outputs = np.array(outputs) >=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:12:25.204961Z",
     "iopub.status.busy": "2020-12-06T13:12:25.204822Z",
     "iopub.status.idle": "2020-12-06T13:12:25.218118Z",
     "shell.execute_reply": "2020-12-06T13:12:25.217628Z",
     "shell.execute_reply.started": "2020-12-06T13:12:25.204943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Score = 0.7239819004524887\n",
      "Hamming Loss = 0.1167420814479638\n"
     ]
    }
   ],
   "source": [
    "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
    "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
    "\n",
    "print(f\"Hamming Score = {val_hamming_score}\")\n",
    "print(f\"Hamming Loss = {val_hamming_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:12:25.218970Z",
     "iopub.status.busy": "2020-12-06T13:12:25.218833Z",
     "iopub.status.idle": "2020-12-06T13:12:25.258706Z",
     "shell.execute_reply": "2020-12-06T13:12:25.258196Z",
     "shell.execute_reply.started": "2020-12-06T13:12:25.218952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.87       719\n",
      "           1       0.71      0.97      0.82       386\n",
      "\n",
      "    accuracy                           0.85      1105\n",
      "   macro avg       0.84      0.87      0.84      1105\n",
      "weighted avg       0.88      0.85      0.85      1105\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94       911\n",
      "           1       0.71      0.84      0.77       194\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.84      0.88      0.86      1105\n",
      "weighted avg       0.92      0.91      0.91      1105\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       974\n",
      "           1       0.38      0.45      0.41       131\n",
      "\n",
      "    accuracy                           0.85      1105\n",
      "   macro avg       0.65      0.68      0.66      1105\n",
      "weighted avg       0.86      0.85      0.85      1105\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       990\n",
      "           1       0.46      0.58      0.51       115\n",
      "\n",
      "    accuracy                           0.88      1105\n",
      "   macro avg       0.70      0.75      0.72      1105\n",
      "weighted avg       0.90      0.88      0.89      1105\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      1105\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89      1105\n",
      "   macro avg       0.50      0.44      0.47      1105\n",
      "weighted avg       1.00      0.89      0.94      1105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "total = len(targets)\n",
    "final = []\n",
    "final_t = []\n",
    "final_fine = [[],[],[],[]]\n",
    "final_fine_t = [[],[],[],[]]\n",
    "for (i,j) in zip(final_outputs, targets):\n",
    "    output_sum = sum(i)\n",
    "    target_sum = sum(j)\n",
    "    if output_sum == 0:\n",
    "        final.append(0)\n",
    "    else:\n",
    "        final.append(1)\n",
    "    if target_sum == 0:\n",
    "        final_t.append(0)\n",
    "    else:\n",
    "        final_t.append(1)\n",
    "    for p in range(4):\n",
    "        final_fine[p].append(int(i[p]))\n",
    "        final_fine_t[p].append(int(j[p]))\n",
    "print(\"Coarse:\")\n",
    "print(classification_report(final, final_t))\n",
    "for i in range(4):\n",
    "    print(\"Fine\", i)\n",
    "    print(classification_report(final_fine[i], final_fine_t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T13:12:25.259514Z",
     "iopub.status.busy": "2020-12-06T13:12:25.259374Z",
     "iopub.status.idle": "2020-12-06T13:12:26.052271Z",
     "shell.execute_reply": "2020-12-06T13:12:26.051575Z",
     "shell.execute_reply.started": "2020-12-06T13:12:25.259495Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f5a253470e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-06T13:12:26.052954Z",
     "iopub.status.idle": "2020-12-06T13:12:26.053168Z"
    }
   },
   "outputs": [],
   "source": [
    "final_fine = [[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-06T13:12:26.053688Z",
     "iopub.status.idle": "2020-12-06T13:12:26.053894Z"
    }
   },
   "outputs": [],
   "source": [
    "final_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
