{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:34.830113Z",
     "iopub.status.busy": "2020-12-06T11:30:34.829891Z",
     "iopub.status.idle": "2020-12-06T11:30:37.982925Z",
     "shell.execute_reply": "2020-12-06T11:30:37.982361Z",
     "shell.execute_reply.started": "2020-12-06T11:30:34.830068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert code here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertConfig, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sent_encoder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:37.984119Z",
     "iopub.status.busy": "2020-12-06T11:30:37.983958Z",
     "iopub.status.idle": "2020-12-06T11:30:38.014648Z",
     "shell.execute_reply": "2020-12-06T11:30:38.014151Z",
     "shell.execute_reply.started": "2020-12-06T11:30:37.984098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:1\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:38.017684Z",
     "iopub.status.busy": "2020-12-06T11:30:38.017532Z",
     "iopub.status.idle": "2020-12-06T11:30:44.033930Z",
     "shell.execute_reply": "2020-12-06T11:30:44.033138Z",
     "shell.execute_reply.started": "2020-12-06T11:30:38.017664Z"
    }
   },
   "outputs": [],
   "source": [
    "models = ['bert-base-multilingual-cased', 'xlm-roberta-base', 'sagorsarker/bangla-bert-base', 'ai4bharat/indic-bert']\n",
    "model_num = 3\n",
    "tokenizer = AutoTokenizer.from_pretrained(models[model_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.035301Z",
     "iopub.status.busy": "2020-12-06T11:30:44.035068Z",
     "iopub.status.idle": "2020-12-06T11:30:44.204446Z",
     "shell.execute_reply": "2020-12-06T11:30:44.203961Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.035216Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train.pickle','rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    train = pd.DataFrame.from_dict(train)\n",
    "with open('valid.pickle','rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    test = pd.DataFrame.from_dict(test)\n",
    "# test = pd.read_csv('data/valid.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.205449Z",
     "iopub.status.busy": "2020-12-06T11:30:44.205285Z",
     "iopub.status.idle": "2020-12-06T11:30:44.260924Z",
     "shell.execute_reply": "2020-12-06T11:30:44.260518Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.205429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>task_1</th>\n",
       "      <th>full_tweet</th>\n",
       "      <th>tweet_raw_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>smiley</th>\n",
       "      <th>emoji</th>\n",
       "      <th>url</th>\n",
       "      <th>mentions</th>\n",
       "      <th>numerals</th>\n",
       "      <th>reserved_word</th>\n",
       "      <th>emotext</th>\n",
       "      <th>segmented_hash</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>4679</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>Poco M2 Pro अब ओपन सेल में उपलब्ध, जानें दाम व...</td>\n",
       "      <td>Poco M2 Pro अब ओपन सेल में उपलब्ध ,  जानें दाम...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/dYMuRBgziu, https://t.co/4nqZTgT...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Poco M2 Pro अब ओपन सेल में उपलब्ध, जानें दाम व...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>5133</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>डॉ. कफील खान पर से हटा NSA, इलाहाबाद HC ने दिय...</td>\n",
       "      <td>डॉ. कफील खान पर से हटा NSA ,  इलाहाबाद HC ने द...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/W5m2FZjYwj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>डॉ. कफील खान पर से हटा NSA, इलाहाबाद HC ने दिय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>768</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>20 साल से जनता के भरोसे पर कायम है आजतक। खबर म...</td>\n",
       "      <td>साल से जनता के भरोसे पर कायम है आजतक। खबर मतलब...</td>\n",
       "      <td>[#Promo, #AajTakNo1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/vc6dVdOZs1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[promo, aaj tak no 1]</td>\n",
       "      <td>20 साल से जनता के भरोसे पर कायम है आजतक। खबर म...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>3275</td>\n",
       "      <td>defamation</td>\n",
       "      <td>गिरी हुई इकोनॉमी देखकर चाइना सोचेगा, ऐसी गिरी ...</td>\n",
       "      <td>गिरी हुई इकोनॉमी देखकर चाइना सोचेगा ,  ऐसी गिर...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>गिरी हुई इकोनॉमी देखकर चाइना सोचेगा, ऐसी गिरी ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>3260</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‘राष्ट्रीय भर्ती एजेंसी‘ पर सरकार का निर्णय भर...</td>\n",
       "      <td>‘राष्ट्रीय भर्ती एजेंसी‘ पर सरकार का निर्णय भर...</td>\n",
       "      <td>[#NTA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/h1QENG8F5V, https://t.co/I9d22U9...</td>\n",
       "      <td>[@DrJitendraSingh]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nta]</td>\n",
       "      <td>‘राष्ट्रीय भर्ती एजेंसी‘ पर सरकार का निर्णय भर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>5595</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>कंगना से विवाद के बीच संजय राउत का ट्वीट, 'मेर...</td>\n",
       "      <td>कंगना से विवाद के बीच संजय राउत का ट्वीट ,  'म...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/8Do3QWQ7Fr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>कंगना से विवाद के बीच संजय राउत का ट्वीट, 'मेर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>CM ठाकुर ने बताया कि 9 सितंबर को कंगना की मुंब...</td>\n",
       "      <td>CM ठाकुर ने बताया कि सितंबर को कंगना की मुंबई ...</td>\n",
       "      <td>[#KanganaRanaut, #HimachalPradesh]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/NHJnhKf8Ba]</td>\n",
       "      <td>[@satenderchauhan]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kangana ranaut, himachal pradesh]</td>\n",
       "      <td>CM ठाकुर ने बताया कि 9 सितंबर को कंगना की मुंब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>1259</td>\n",
       "      <td>fake</td>\n",
       "      <td>*#जयपुर का #राज-मन्दिर #सिनेमाहॉल बिका...#*  *...</td>\n",
       "      <td>*#जयपुर का #राज-मन्दिर #सिनेमाहॉल बिका...#*  *...</td>\n",
       "      <td>[#जयप, #र, #स, #, #प, #, #एश, #, #र, #]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 30]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[जयप, र, स, , प, , एश, , र, ]</td>\n",
       "      <td>* ुर का  ाज-मन्दिर  िनेमाहॉल बिका... *  * प्रा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1019</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>....से सम्बन्धित परास्नातक के छात्रों को अनुमत...</td>\n",
       "      <td>....से सम्बन्धित परास्नातक के छात्रों को अनुमत...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@AwasthiAwanishK]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>....से सम्बन्धित परास्नातक के छात्रों को अनुमत...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1704</td>\n",
       "      <td>defamation,hate,offensive</td>\n",
       "      <td>@Samrehman03 .@Samrehman03  बहुत बड़ा कमीना है...</td>\n",
       "      <td>.@Samrehman03  बहुत बड़ा कमीना है ये ,  सिर्फ ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[🙄]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@Samrehman03, @Samrehman03]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[face with rolling eyes]</td>\n",
       "      <td>[]</td>\n",
       "      <td>.   बहुत बड़ा कमीना है ये, सिर्फ हिन्दू भाइय...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1415</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>कुशीनगर से दो माह में अंतरराष्ट्रीय उड़ान: मुख...</td>\n",
       "      <td>कुशीनगर से दो माह में अंतरराष्ट्रीय उड़ान :  म...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/RszRfoKFXG]</td>\n",
       "      <td>[@myogiadityanath]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>कुशीनगर से दो माह में अंतरराष्ट्रीय उड़ान: मुख...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>5658</td>\n",
       "      <td>defamation</td>\n",
       "      <td>पाकिस्तानी सेना ने भारतीय सेना द्वारा ईद पर भे...</td>\n",
       "      <td>पाकिस्तानी सेना ने भारतीय सेना द्वारा ईद पर भे...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>पाकिस्तानी सेना ने भारतीय सेना द्वारा ईद पर भे...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>3584</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>वरिष्ठ वकील प्रशांत भूषण बोले, मेरे ट्वीट्स का...</td>\n",
       "      <td>वरिष्ठ वकील प्रशांत भूषण बोले ,  मेरे ट्वीट्स ...</td>\n",
       "      <td>[#PrashantBhushanCase, #SupremeCourt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/fSXXQsF3yg]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[prashant bhushan case, supreme court]</td>\n",
       "      <td>वरिष्ठ वकील प्रशांत भूषण बोले, मेरे ट्वीट्स का...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>4602</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>ये ऐसा सेल्फ़ी कैमरा है, जो मौजूद तो है, मगर द...</td>\n",
       "      <td>ये ऐसा सेल्फ़ी कैमरा है ,  जो मौजूद तो है ,  म...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/qOl0fcBCIC]</td>\n",
       "      <td>[@itsmeFSL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ये ऐसा सेल्फ़ी कैमरा है, जो मौजूद तो है, मगर द...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>4120</td>\n",
       "      <td>fake</td>\n",
       "      <td>चीन में चार किमी अंदर घुस चुकी हैं भारत की सेन...</td>\n",
       "      <td>चीन में चार किमी अंदर घुस चुकी हैं भारत की सेन...</td>\n",
       "      <td>[#ModiHaiToMumkinHai]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@INCIndia, @ippatel]</td>\n",
       "      <td>[1962, 57]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[modi hai to mumkin hai]</td>\n",
       "      <td>चीन में चार किमी अंदर घुस चुकी हैं भारत की सेन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>3988</td>\n",
       "      <td>hate</td>\n",
       "      <td>धूल चटा दो गिद्धों को ,जो घर में घुस कर घात कर...</td>\n",
       "      <td>धूल चटा दो गिद्धों को  , जो घर में घुस कर घात ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[🚩, 🚩, 🙏]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[triangular flag, triangular flag, folded hands]</td>\n",
       "      <td>[]</td>\n",
       "      <td>धूल चटा दो गिद्धों को ,जो घर में घुस कर घात कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>बैंकिग सिस्टम में इस समय बैंकों का कुल बकाया क...</td>\n",
       "      <td>बैंकिग सिस्टम में इस समय बैंकों का कुल बकाया क...</td>\n",
       "      <td>[#HindiNews]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/AvWQ7l7kA8]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[hindi news]</td>\n",
       "      <td>बैंकिग सिस्टम में इस समय बैंकों का कुल बकाया क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1684</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@JayHind11544289 जय हिन्द की सेना..👌👏👏👍 और जो ...</td>\n",
       "      <td>जय हिन्द की सेना..👌👏👏👍 और जो नालायक देश द्रोही...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[👌, 👏, 👏, 👍, 😠, 😠]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@JayHind11544289]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[OK hand, clapping hands, clapping hands, thum...</td>\n",
       "      <td>[]</td>\n",
       "      <td>जय हिन्द की सेना..     और जो नालायक देश द्रो...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>4843</td>\n",
       "      <td>defamation</td>\n",
       "      <td>ये कांग्रेस वाले, अध्यक्ष पद वाला ड्रामा समय  ...</td>\n",
       "      <td>ये कांग्रेस वाले ,  अध्यक्ष पद वाला ड्रामा समय...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[😂, 😂, 😂, 😜, 😜, 😜]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[face with tears of joy, face with tears of jo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>ये कांग्रेस वाले, अध्यक्ष पद वाला ड्रामा समय  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2134</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>दिल्ली मॉडल की एक और पहल https://t.co/lOuMTPDfXr</td>\n",
       "      <td>दिल्ली मॉडल की एक और पहल https : //t.co/lOuMTP...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/lOuMTPDfXr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>दिल्ली मॉडल की एक और पहल</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id                     task_1  \\\n",
       "4564     4679                non-hostile   \n",
       "4932     5133                non-hostile   \n",
       "768       768                non-hostile   \n",
       "3160     3275                 defamation   \n",
       "3145     3260                non-hostile   \n",
       "5394     5595                non-hostile   \n",
       "835       835                non-hostile   \n",
       "1192     1259                       fake   \n",
       "1019     1019                non-hostile   \n",
       "1637     1704  defamation,hate,offensive   \n",
       "1348     1415                non-hostile   \n",
       "5457     5658                 defamation   \n",
       "3469     3584                non-hostile   \n",
       "4487     4602                non-hostile   \n",
       "4005     4120                       fake   \n",
       "3873     3988                       hate   \n",
       "261       261                non-hostile   \n",
       "1617     1684                  offensive   \n",
       "4728     4843                 defamation   \n",
       "2067     2134                non-hostile   \n",
       "\n",
       "                                             full_tweet  \\\n",
       "4564  Poco M2 Pro अब ओपन सेल में उपलब्ध, जानें दाम व...   \n",
       "4932  डॉ. कफील खान पर से हटा NSA, इलाहाबाद HC ने दिय...   \n",
       "768   20 साल से जनता के भरोसे पर कायम है आजतक। खबर म...   \n",
       "3160  गिरी हुई इकोनॉमी देखकर चाइना सोचेगा, ऐसी गिरी ...   \n",
       "3145  ‘राष्ट्रीय भर्ती एजेंसी‘ पर सरकार का निर्णय भर...   \n",
       "5394  कंगना से विवाद के बीच संजय राउत का ट्वीट, 'मेर...   \n",
       "835   CM ठाकुर ने बताया कि 9 सितंबर को कंगना की मुंब...   \n",
       "1192  *#जयपुर का #राज-मन्दिर #सिनेमाहॉल बिका...#*  *...   \n",
       "1019  ....से सम्बन्धित परास्नातक के छात्रों को अनुमत...   \n",
       "1637  @Samrehman03 .@Samrehman03  बहुत बड़ा कमीना है...   \n",
       "1348  कुशीनगर से दो माह में अंतरराष्ट्रीय उड़ान: मुख...   \n",
       "5457  पाकिस्तानी सेना ने भारतीय सेना द्वारा ईद पर भे...   \n",
       "3469  वरिष्ठ वकील प्रशांत भूषण बोले, मेरे ट्वीट्स का...   \n",
       "4487  ये ऐसा सेल्फ़ी कैमरा है, जो मौजूद तो है, मगर द...   \n",
       "4005  चीन में चार किमी अंदर घुस चुकी हैं भारत की सेन...   \n",
       "3873  धूल चटा दो गिद्धों को ,जो घर में घुस कर घात कर...   \n",
       "261   बैंकिग सिस्टम में इस समय बैंकों का कुल बकाया क...   \n",
       "1617  @JayHind11544289 जय हिन्द की सेना..👌👏👏👍 और जो ...   \n",
       "4728  ये कांग्रेस वाले, अध्यक्ष पद वाला ड्रामा समय  ...   \n",
       "2067   दिल्ली मॉडल की एक और पहल https://t.co/lOuMTPDfXr   \n",
       "\n",
       "                                         tweet_raw_text  \\\n",
       "4564  Poco M2 Pro अब ओपन सेल में उपलब्ध ,  जानें दाम...   \n",
       "4932  डॉ. कफील खान पर से हटा NSA ,  इलाहाबाद HC ने द...   \n",
       "768   साल से जनता के भरोसे पर कायम है आजतक। खबर मतलब...   \n",
       "3160  गिरी हुई इकोनॉमी देखकर चाइना सोचेगा ,  ऐसी गिर...   \n",
       "3145  ‘राष्ट्रीय भर्ती एजेंसी‘ पर सरकार का निर्णय भर...   \n",
       "5394  कंगना से विवाद के बीच संजय राउत का ट्वीट ,  'म...   \n",
       "835   CM ठाकुर ने बताया कि सितंबर को कंगना की मुंबई ...   \n",
       "1192  *#जयपुर का #राज-मन्दिर #सिनेमाहॉल बिका...#*  *...   \n",
       "1019  ....से सम्बन्धित परास्नातक के छात्रों को अनुमत...   \n",
       "1637  .@Samrehman03  बहुत बड़ा कमीना है ये ,  सिर्फ ...   \n",
       "1348  कुशीनगर से दो माह में अंतरराष्ट्रीय उड़ान :  म...   \n",
       "5457  पाकिस्तानी सेना ने भारतीय सेना द्वारा ईद पर भे...   \n",
       "3469  वरिष्ठ वकील प्रशांत भूषण बोले ,  मेरे ट्वीट्स ...   \n",
       "4487  ये ऐसा सेल्फ़ी कैमरा है ,  जो मौजूद तो है ,  म...   \n",
       "4005  चीन में चार किमी अंदर घुस चुकी हैं भारत की सेन...   \n",
       "3873  धूल चटा दो गिद्धों को  , जो घर में घुस कर घात ...   \n",
       "261   बैंकिग सिस्टम में इस समय बैंकों का कुल बकाया क...   \n",
       "1617  जय हिन्द की सेना..👌👏👏👍 और जो नालायक देश द्रोही...   \n",
       "4728  ये कांग्रेस वाले ,  अध्यक्ष पद वाला ड्रामा समय...   \n",
       "2067  दिल्ली मॉडल की एक और पहल https : //t.co/lOuMTP...   \n",
       "\n",
       "                                     hashtags smiley               emoji  \\\n",
       "4564                                       []     []                  []   \n",
       "4932                                       []     []                  []   \n",
       "768                      [#Promo, #AajTakNo1]     []                  []   \n",
       "3160                                       []     []                  []   \n",
       "3145                                   [#NTA]     []                  []   \n",
       "5394                                       []     []                  []   \n",
       "835        [#KanganaRanaut, #HimachalPradesh]     []                  []   \n",
       "1192  [#जयप, #र, #स, #, #प, #, #एश, #, #र, #]     []                  []   \n",
       "1019                                       []     []                  []   \n",
       "1637                                       []     []                 [🙄]   \n",
       "1348                                       []     []                  []   \n",
       "5457                                       []     []                  []   \n",
       "3469    [#PrashantBhushanCase, #SupremeCourt]     []                  []   \n",
       "4487                                       []     []                  []   \n",
       "4005                    [#ModiHaiToMumkinHai]     []                  []   \n",
       "3873                                       []     []           [🚩, 🚩, 🙏]   \n",
       "261                              [#HindiNews]     []                  []   \n",
       "1617                                       []     []  [👌, 👏, 👏, 👍, 😠, 😠]   \n",
       "4728                                       []     []  [😂, 😂, 😂, 😜, 😜, 😜]   \n",
       "2067                                       []     []                  []   \n",
       "\n",
       "                                                    url  \\\n",
       "4564  [https://t.co/dYMuRBgziu, https://t.co/4nqZTgT...   \n",
       "4932                          [https://t.co/W5m2FZjYwj]   \n",
       "768                           [https://t.co/vc6dVdOZs1]   \n",
       "3160                                                 []   \n",
       "3145  [https://t.co/h1QENG8F5V, https://t.co/I9d22U9...   \n",
       "5394                          [https://t.co/8Do3QWQ7Fr]   \n",
       "835                           [https://t.co/NHJnhKf8Ba]   \n",
       "1192                                                 []   \n",
       "1019                                                 []   \n",
       "1637                                                 []   \n",
       "1348                          [https://t.co/RszRfoKFXG]   \n",
       "5457                                                 []   \n",
       "3469                          [https://t.co/fSXXQsF3yg]   \n",
       "4487                          [https://t.co/qOl0fcBCIC]   \n",
       "4005                                                 []   \n",
       "3873                                                 []   \n",
       "261                           [https://t.co/AvWQ7l7kA8]   \n",
       "1617                                                 []   \n",
       "4728                                                 []   \n",
       "2067                          [https://t.co/lOuMTPDfXr]   \n",
       "\n",
       "                          mentions    numerals reserved_word  \\\n",
       "4564                            []          []            []   \n",
       "4932                            []          []            []   \n",
       "768                             []        [20]            []   \n",
       "3160                            []          []            []   \n",
       "3145            [@DrJitendraSingh]          []            []   \n",
       "5394                            []          []            []   \n",
       "835             [@satenderchauhan]         [9]            []   \n",
       "1192                            []     [1, 30]            []   \n",
       "1019            [@AwasthiAwanishK]          []            []   \n",
       "1637  [@Samrehman03, @Samrehman03]          []            []   \n",
       "1348            [@myogiadityanath]          []            []   \n",
       "5457                            []          []            []   \n",
       "3469                            []          []            []   \n",
       "4487                   [@itsmeFSL]          []            []   \n",
       "4005         [@INCIndia, @ippatel]  [1962, 57]            []   \n",
       "3873                            []          []            []   \n",
       "261                             []       [100]            []   \n",
       "1617            [@JayHind11544289]          []            []   \n",
       "4728                            []          []            []   \n",
       "2067                            []          []            []   \n",
       "\n",
       "                                                emotext  \\\n",
       "4564                                                 []   \n",
       "4932                                                 []   \n",
       "768                                                  []   \n",
       "3160                                                 []   \n",
       "3145                                                 []   \n",
       "5394                                                 []   \n",
       "835                                                  []   \n",
       "1192                                                 []   \n",
       "1019                                                 []   \n",
       "1637                           [face with rolling eyes]   \n",
       "1348                                                 []   \n",
       "5457                                                 []   \n",
       "3469                                                 []   \n",
       "4487                                                 []   \n",
       "4005                                                 []   \n",
       "3873   [triangular flag, triangular flag, folded hands]   \n",
       "261                                                  []   \n",
       "1617  [OK hand, clapping hands, clapping hands, thum...   \n",
       "4728  [face with tears of joy, face with tears of jo...   \n",
       "2067                                                 []   \n",
       "\n",
       "                              segmented_hash  \\\n",
       "4564                                      []   \n",
       "4932                                      []   \n",
       "768                    [promo, aaj tak no 1]   \n",
       "3160                                      []   \n",
       "3145                                   [nta]   \n",
       "5394                                      []   \n",
       "835       [kangana ranaut, himachal pradesh]   \n",
       "1192           [जयप, र, स, , प, , एश, , र, ]   \n",
       "1019                                      []   \n",
       "1637                                      []   \n",
       "1348                                      []   \n",
       "5457                                      []   \n",
       "3469  [prashant bhushan case, supreme court]   \n",
       "4487                                      []   \n",
       "4005                [modi hai to mumkin hai]   \n",
       "3873                                      []   \n",
       "261                             [hindi news]   \n",
       "1617                                      []   \n",
       "4728                                      []   \n",
       "2067                                      []   \n",
       "\n",
       "                                                  clean  \n",
       "4564  Poco M2 Pro अब ओपन सेल में उपलब्ध, जानें दाम व...  \n",
       "4932  डॉ. कफील खान पर से हटा NSA, इलाहाबाद HC ने दिय...  \n",
       "768   20 साल से जनता के भरोसे पर कायम है आजतक। खबर म...  \n",
       "3160  गिरी हुई इकोनॉमी देखकर चाइना सोचेगा, ऐसी गिरी ...  \n",
       "3145  ‘राष्ट्रीय भर्ती एजेंसी‘ पर सरकार का निर्णय भर...  \n",
       "5394  कंगना से विवाद के बीच संजय राउत का ट्वीट, 'मेर...  \n",
       "835   CM ठाकुर ने बताया कि 9 सितंबर को कंगना की मुंब...  \n",
       "1192  * ुर का  ाज-मन्दिर  िनेमाहॉल बिका... *  * प्रा...  \n",
       "1019  ....से सम्बन्धित परास्नातक के छात्रों को अनुमत...  \n",
       "1637    .   बहुत बड़ा कमीना है ये, सिर्फ हिन्दू भाइय...  \n",
       "1348  कुशीनगर से दो माह में अंतरराष्ट्रीय उड़ान: मुख...  \n",
       "5457  पाकिस्तानी सेना ने भारतीय सेना द्वारा ईद पर भे...  \n",
       "3469  वरिष्ठ वकील प्रशांत भूषण बोले, मेरे ट्वीट्स का...  \n",
       "4487  ये ऐसा सेल्फ़ी कैमरा है, जो मौजूद तो है, मगर द...  \n",
       "4005  चीन में चार किमी अंदर घुस चुकी हैं भारत की सेन...  \n",
       "3873  धूल चटा दो गिद्धों को ,जो घर में घुस कर घात कर...  \n",
       "261   बैंकिग सिस्टम में इस समय बैंकों का कुल बकाया क...  \n",
       "1617    जय हिन्द की सेना..     और जो नालायक देश द्रो...  \n",
       "4728  ये कांग्रेस वाले, अध्यक्ष पद वाला ड्रामा समय  ...  \n",
       "2067                         दिल्ली मॉडल की एक और पहल    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.261940Z",
     "iopub.status.busy": "2020-12-06T11:30:44.261774Z",
     "iopub.status.idle": "2020-12-06T11:30:44.265726Z",
     "shell.execute_reply": "2020-12-06T11:30:44.265318Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.261920Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_labels(label):\n",
    "    tmp = label.split(',')\n",
    "    ls = [0, 0, 0, 0]\n",
    "    if tmp[0] == 'non-hostile':\n",
    "        return ls\n",
    "    if 'fake' in tmp:\n",
    "        ls[0] = 1\n",
    "    if 'hate' in tmp:\n",
    "        ls[1] = 1\n",
    "    if 'offensive' in tmp:\n",
    "        ls[2] = 1\n",
    "    if 'defamation' in tmp:\n",
    "        ls[3] = 1\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.266578Z",
     "iopub.status.busy": "2020-12-06T11:30:44.266426Z",
     "iopub.status.idle": "2020-12-06T11:30:44.275241Z",
     "shell.execute_reply": "2020-12-06T11:30:44.274769Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.266559Z"
    }
   },
   "outputs": [],
   "source": [
    "train['encodelabels'] = train['task_1'].apply(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.277178Z",
     "iopub.status.busy": "2020-12-06T11:30:44.277024Z",
     "iopub.status.idle": "2020-12-06T11:30:44.332943Z",
     "shell.execute_reply": "2020-12-06T11:30:44.332475Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.277158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>task_1</th>\n",
       "      <th>full_tweet</th>\n",
       "      <th>tweet_raw_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>smiley</th>\n",
       "      <th>emoji</th>\n",
       "      <th>url</th>\n",
       "      <th>mentions</th>\n",
       "      <th>numerals</th>\n",
       "      <th>reserved_word</th>\n",
       "      <th>emotext</th>\n",
       "      <th>segmented_hash</th>\n",
       "      <th>clean</th>\n",
       "      <th>encodelabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>hate</td>\n",
       "      <td>@Sabir51861509 पुलिस आपके लिए नहीं बनी है न्या...</td>\n",
       "      <td>पुलिस आपके लिए नहीं बनी है न्यायपालिका आपके लि...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@Sabir51861509]</td>\n",
       "      <td>[10, 10, 90]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>पुलिस आपके लिए नहीं बनी है न्यायपालिका आपके ...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1276</td>\n",
       "      <td>fake</td>\n",
       "      <td>15 जून की रात गलवान घाटी पर हुई उस मुठभेड़। तिर...</td>\n",
       "      <td>जून की रात गलवान घाटी पर हुई उस मुठभेड़। तिरंगे...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>15 जून की रात गलवान घाटी पर हुई उस मुठभेड़। तिर...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>2748</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>पुलिस कस्टडी से बीएचयू के छात्र के लापता होने ...</td>\n",
       "      <td>पुलिस कस्टडी से बीएचयू के छात्र के लापता होने ...</td>\n",
       "      <td>[#Allahabad]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/EpjUpwojjr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[allahabad]</td>\n",
       "      <td>पुलिस कस्टडी से बीएचयू के छात्र के लापता होने ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>बधाई हो मोदी जी आपकी मन की बात को पूरे 100 हज़...</td>\n",
       "      <td>बधाई हो मोदी जी आपकी मन की बात को पूरे हज़ार ड...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[😂]</td>\n",
       "      <td>[https://t.co/BUEX28Lfpe]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[face with tears of joy]</td>\n",
       "      <td>[]</td>\n",
       "      <td>बधाई हो मोदी जी आपकी मन की बात को पूरे 100 हज़...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>2975</td>\n",
       "      <td>fake</td>\n",
       "      <td>नोवल कोरोनावायरस से संक्रमित 20,000 से अधिक रो...</td>\n",
       "      <td>नोवल कोरोनावायरस से संक्रमित 20 , 000 से अधिक ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[20,000]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>नोवल कोरोनावायरस से संक्रमित 20,000 से अधिक रो...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>805</td>\n",
       "      <td>fake</td>\n",
       "      <td>पाकिस्तान में शेष बचे हिन्दुओं के लिए भी कोई म...</td>\n",
       "      <td>पाकिस्तान में शेष बचे हिन्दुओं के लिए भी कोई म...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>पाकिस्तान में शेष बचे हिन्दुओं के लिए भी कोई म...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>4150</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>रेल मंत्री @PiyushGoyal ने मुंबई में #NEET_JEE...</td>\n",
       "      <td>रेल मंत्री ने मुंबई में की परीक्षा देने वाले छ...</td>\n",
       "      <td>[#NEET_JEE]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/ly7wl5QP6l]</td>\n",
       "      <td>[@PiyushGoyal, @RailMinIndia]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[neet _ jee]</td>\n",
       "      <td>रेल मंत्री   ने मुंबई में   की परीक्षा देने वा...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>5209</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>विराट कोहली को टीम इंडिया से बाहर करने की आवाज...</td>\n",
       "      <td>विराट कोहली को टीम इंडिया से बाहर करने की आवाज...</td>\n",
       "      <td>[#MSDhoni]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/6T2VP0pf7e]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ms dhoni]</td>\n",
       "      <td>विराट कोहली को टीम इंडिया से बाहर करने की आवाज...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>3362</td>\n",
       "      <td>offensive</td>\n",
       "      <td>हिन्दुत्व की जो नींव मोदीजी ने रखी है. यकीन रख...</td>\n",
       "      <td>हिन्दुत्व की जो नींव मोदीजी ने रखी है. यकीन रख...</td>\n",
       "      <td>[#रण_म]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[🚩, 🚩]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[triangular flag, triangular flag]</td>\n",
       "      <td>[रण _म]</td>\n",
       "      <td>हिन्दुत्व की जो नींव मोदीजी ने रखी है. यकीन रख...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>2455</td>\n",
       "      <td>fake</td>\n",
       "      <td>यह ख़बर जो एजेंट मीडिया नहीं चलाएगा । दक्षिण अम...</td>\n",
       "      <td>यह ख़बर जो एजेंट मीडिया नहीं चलाएगा । दक्षिण अम...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>यह ख़बर जो एजेंट मीडिया नहीं चलाएगा । दक्षिण अम...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>3330</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>दिल्ली: प्रधानमंत्री नरेंद्र मोदी ने पूर्व राष...</td>\n",
       "      <td>दिल्ली :  प्रधानमंत्री नरेंद्र मोदी ने पूर्व र...</td>\n",
       "      <td>[#PranabMukherjee]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/KFnDD9ZjmA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pranab mukherjee]</td>\n",
       "      <td>दिल्ली: प्रधानमंत्री नरेंद्र मोदी ने पूर्व राष...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>offensive</td>\n",
       "      <td>जिनका एक बाण समंदर तक को सोख सकता है,  अयोध्या...</td>\n",
       "      <td>जिनका एक बाण समंदर तक को सोख सकता है ,   अयोध्...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[🔥, 🚩]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fire, triangular flag]</td>\n",
       "      <td>[]</td>\n",
       "      <td>जिनका एक बाण समंदर तक को सोख सकता है,  अयोध्या...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>3873</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>अमेरिकी अंतरिक्ष एजेंसी नासा ने ब्रह्मांड की क...</td>\n",
       "      <td>अमेरिकी अंतरिक्ष एजेंसी नासा ने ब्रह्मांड की क...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/zUhyPfXZtV]</td>\n",
       "      <td>[@NASA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>अमेरिकी अंतरिक्ष एजेंसी नासा ने ब्रह्मांड की क...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>1257</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>#WeatherUpdates : दिल्ली समेत देश के कई हिस्सो...</td>\n",
       "      <td>:  दिल्ली समेत देश के कई हिस्सों में होगी झमाझ...</td>\n",
       "      <td>[#WeatherUpdates, #IMD, #WeatherForecast]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/pPO3WjiqKy]</td>\n",
       "      <td>[@IMDWeather]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[weather updates, imd, weather forecast]</td>\n",
       "      <td>: दिल्ली समेत देश के कई हिस्सों में होगी झमा...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unique ID</td>\n",
       "      <td>Labels Set</td>\n",
       "      <td>Post</td>\n",
       "      <td>Post</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Post</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>4267</td>\n",
       "      <td>hate,offensive</td>\n",
       "      <td>मुगलों ने साम दाम दंड भेद द्वारा हिंदुओं का धर...</td>\n",
       "      <td>मुगलों ने साम दाम दंड भेद द्वारा हिंदुओं का धर...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>मुगलों ने साम दाम दंड भेद द्वारा हिंदुओं का धर...</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>5497</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>#SushantSinghRajput की कॉल रिकॉर्ड से पता चला ...</td>\n",
       "      <td>की कॉल रिकॉर्ड से पता चला है कि वे अपने पिता क...</td>\n",
       "      <td>[#SushantSinghRajput]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/yaJg6GQCCW]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sushant singh rajput]</td>\n",
       "      <td>की कॉल रिकॉर्ड से पता चला है कि वे अपने पिता...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>असली हीरो की आवाज में  सुनिए \"तेरी मिट्टी में ...</td>\n",
       "      <td>असली हीरो की आवाज में  सुनिए \"तेरी मिट्टी में ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/69wERP7uQl]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>असली हीरो की आवाज में  सुनिए \"तेरी मिट्टी में ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>2678</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@sambitswaraj ये सब साले गली के कुत्ते  से भी ...</td>\n",
       "      <td>ये सब साले गली के कुत्ते  से भी बेकार है।</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@sambitswaraj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>ये सब साले गली के कुत्ते  से भी बेकार है।</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td>defamation</td>\n",
       "      <td>#हीरखान उर्फ़ परी खान को जल्द ही Arrest  करें ...</td>\n",
       "      <td>#हीरखान उर्फ़ परी खान को जल्द ही Arrest  करें ...</td>\n",
       "      <td>[#ह, #Justस, #Arrestheerkhan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ह, justस, arrestheerkhan]</td>\n",
       "      <td>ीरखान उर्फ़ परी खान को जल्द ही Arrest  करें क...</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id          task_1  \\\n",
       "719         719            hate   \n",
       "1209       1276            fake   \n",
       "2633       2748     non-hostile   \n",
       "43           43     non-hostile   \n",
       "2860       2975            fake   \n",
       "805         805            fake   \n",
       "4035       4150     non-hostile   \n",
       "5008       5209     non-hostile   \n",
       "3247       3362       offensive   \n",
       "2340       2455            fake   \n",
       "3215       3330     non-hostile   \n",
       "653         653       offensive   \n",
       "3758       3873     non-hostile   \n",
       "1190       1257     non-hostile   \n",
       "0     Unique ID      Labels Set   \n",
       "4152       4267  hate,offensive   \n",
       "5296       5497     non-hostile   \n",
       "583         583     non-hostile   \n",
       "2563       2678       offensive   \n",
       "873         873      defamation   \n",
       "\n",
       "                                             full_tweet  \\\n",
       "719   @Sabir51861509 पुलिस आपके लिए नहीं बनी है न्या...   \n",
       "1209  15 जून की रात गलवान घाटी पर हुई उस मुठभेड़। तिर...   \n",
       "2633  पुलिस कस्टडी से बीएचयू के छात्र के लापता होने ...   \n",
       "43    बधाई हो मोदी जी आपकी मन की बात को पूरे 100 हज़...   \n",
       "2860  नोवल कोरोनावायरस से संक्रमित 20,000 से अधिक रो...   \n",
       "805   पाकिस्तान में शेष बचे हिन्दुओं के लिए भी कोई म...   \n",
       "4035  रेल मंत्री @PiyushGoyal ने मुंबई में #NEET_JEE...   \n",
       "5008  विराट कोहली को टीम इंडिया से बाहर करने की आवाज...   \n",
       "3247  हिन्दुत्व की जो नींव मोदीजी ने रखी है. यकीन रख...   \n",
       "2340  यह ख़बर जो एजेंट मीडिया नहीं चलाएगा । दक्षिण अम...   \n",
       "3215  दिल्ली: प्रधानमंत्री नरेंद्र मोदी ने पूर्व राष...   \n",
       "653   जिनका एक बाण समंदर तक को सोख सकता है,  अयोध्या...   \n",
       "3758  अमेरिकी अंतरिक्ष एजेंसी नासा ने ब्रह्मांड की क...   \n",
       "1190  #WeatherUpdates : दिल्ली समेत देश के कई हिस्सो...   \n",
       "0                                                  Post   \n",
       "4152  मुगलों ने साम दाम दंड भेद द्वारा हिंदुओं का धर...   \n",
       "5296  #SushantSinghRajput की कॉल रिकॉर्ड से पता चला ...   \n",
       "583   असली हीरो की आवाज में  सुनिए \"तेरी मिट्टी में ...   \n",
       "2563  @sambitswaraj ये सब साले गली के कुत्ते  से भी ...   \n",
       "873   #हीरखान उर्फ़ परी खान को जल्द ही Arrest  करें ...   \n",
       "\n",
       "                                         tweet_raw_text  \\\n",
       "719   पुलिस आपके लिए नहीं बनी है न्यायपालिका आपके लि...   \n",
       "1209  जून की रात गलवान घाटी पर हुई उस मुठभेड़। तिरंगे...   \n",
       "2633  पुलिस कस्टडी से बीएचयू के छात्र के लापता होने ...   \n",
       "43    बधाई हो मोदी जी आपकी मन की बात को पूरे हज़ार ड...   \n",
       "2860  नोवल कोरोनावायरस से संक्रमित 20 , 000 से अधिक ...   \n",
       "805   पाकिस्तान में शेष बचे हिन्दुओं के लिए भी कोई म...   \n",
       "4035  रेल मंत्री ने मुंबई में की परीक्षा देने वाले छ...   \n",
       "5008  विराट कोहली को टीम इंडिया से बाहर करने की आवाज...   \n",
       "3247  हिन्दुत्व की जो नींव मोदीजी ने रखी है. यकीन रख...   \n",
       "2340  यह ख़बर जो एजेंट मीडिया नहीं चलाएगा । दक्षिण अम...   \n",
       "3215  दिल्ली :  प्रधानमंत्री नरेंद्र मोदी ने पूर्व र...   \n",
       "653   जिनका एक बाण समंदर तक को सोख सकता है ,   अयोध्...   \n",
       "3758  अमेरिकी अंतरिक्ष एजेंसी नासा ने ब्रह्मांड की क...   \n",
       "1190  :  दिल्ली समेत देश के कई हिस्सों में होगी झमाझ...   \n",
       "0                                                  Post   \n",
       "4152  मुगलों ने साम दाम दंड भेद द्वारा हिंदुओं का धर...   \n",
       "5296  की कॉल रिकॉर्ड से पता चला है कि वे अपने पिता क...   \n",
       "583   असली हीरो की आवाज में  सुनिए \"तेरी मिट्टी में ...   \n",
       "2563          ये सब साले गली के कुत्ते  से भी बेकार है।   \n",
       "873   #हीरखान उर्फ़ परी खान को जल्द ही Arrest  करें ...   \n",
       "\n",
       "                                       hashtags smiley   emoji  \\\n",
       "719                                          []     []      []   \n",
       "1209                                         []     []      []   \n",
       "2633                               [#Allahabad]     []      []   \n",
       "43                                           []     []     [😂]   \n",
       "2860                                         []     []      []   \n",
       "805                                          []     []      []   \n",
       "4035                                [#NEET_JEE]     []      []   \n",
       "5008                                 [#MSDhoni]     []      []   \n",
       "3247                                    [#रण_म]     []  [🚩, 🚩]   \n",
       "2340                                         []     []      []   \n",
       "3215                         [#PranabMukherjee]     []      []   \n",
       "653                                          []     []  [🔥, 🚩]   \n",
       "3758                                         []     []      []   \n",
       "1190  [#WeatherUpdates, #IMD, #WeatherForecast]     []      []   \n",
       "0                                            []     []      []   \n",
       "4152                                         []     []      []   \n",
       "5296                      [#SushantSinghRajput]     []      []   \n",
       "583                                          []     []      []   \n",
       "2563                                         []     []      []   \n",
       "873               [#ह, #Justस, #Arrestheerkhan]     []      []   \n",
       "\n",
       "                            url                       mentions      numerals  \\\n",
       "719                          []               [@Sabir51861509]  [10, 10, 90]   \n",
       "1209                         []                             []          [15]   \n",
       "2633  [https://t.co/EpjUpwojjr]                             []            []   \n",
       "43    [https://t.co/BUEX28Lfpe]                             []         [100]   \n",
       "2860                         []                             []      [20,000]   \n",
       "805                          []                             []            []   \n",
       "4035  [https://t.co/ly7wl5QP6l]  [@PiyushGoyal, @RailMinIndia]            []   \n",
       "5008  [https://t.co/6T2VP0pf7e]                             []            []   \n",
       "3247                         []                             []            []   \n",
       "2340                         []                             []            []   \n",
       "3215  [https://t.co/KFnDD9ZjmA]                             []          [10]   \n",
       "653                          []                             []            []   \n",
       "3758  [https://t.co/zUhyPfXZtV]                        [@NASA]            []   \n",
       "1190  [https://t.co/pPO3WjiqKy]                  [@IMDWeather]            []   \n",
       "0                            []                             []            []   \n",
       "4152                         []                             []            []   \n",
       "5296  [https://t.co/yaJg6GQCCW]                             []            []   \n",
       "583   [https://t.co/69wERP7uQl]                             []            []   \n",
       "2563                         []                [@sambitswaraj]            []   \n",
       "873                          []                             []            []   \n",
       "\n",
       "     reserved_word                             emotext  \\\n",
       "719             []                                  []   \n",
       "1209            []                                  []   \n",
       "2633            []                                  []   \n",
       "43              []            [face with tears of joy]   \n",
       "2860            []                                  []   \n",
       "805             []                                  []   \n",
       "4035            []                                  []   \n",
       "5008            []                                  []   \n",
       "3247            []  [triangular flag, triangular flag]   \n",
       "2340            []                                  []   \n",
       "3215            []                                  []   \n",
       "653             []             [fire, triangular flag]   \n",
       "3758            []                                  []   \n",
       "1190            []                                  []   \n",
       "0               []                                  []   \n",
       "4152            []                                  []   \n",
       "5296            []                                  []   \n",
       "583             []                                  []   \n",
       "2563            []                                  []   \n",
       "873             []                                  []   \n",
       "\n",
       "                                segmented_hash  \\\n",
       "719                                         []   \n",
       "1209                                        []   \n",
       "2633                               [allahabad]   \n",
       "43                                          []   \n",
       "2860                                        []   \n",
       "805                                         []   \n",
       "4035                              [neet _ jee]   \n",
       "5008                                [ms dhoni]   \n",
       "3247                                   [रण _म]   \n",
       "2340                                        []   \n",
       "3215                        [pranab mukherjee]   \n",
       "653                                         []   \n",
       "3758                                        []   \n",
       "1190  [weather updates, imd, weather forecast]   \n",
       "0                                           []   \n",
       "4152                                        []   \n",
       "5296                    [sushant singh rajput]   \n",
       "583                                         []   \n",
       "2563                                        []   \n",
       "873                 [ह, justस, arrestheerkhan]   \n",
       "\n",
       "                                                  clean  encodelabels  \n",
       "719     पुलिस आपके लिए नहीं बनी है न्यायपालिका आपके ...  [0, 1, 0, 0]  \n",
       "1209  15 जून की रात गलवान घाटी पर हुई उस मुठभेड़। तिर...  [1, 0, 0, 0]  \n",
       "2633  पुलिस कस्टडी से बीएचयू के छात्र के लापता होने ...  [0, 0, 0, 0]  \n",
       "43    बधाई हो मोदी जी आपकी मन की बात को पूरे 100 हज़...  [0, 0, 0, 0]  \n",
       "2860  नोवल कोरोनावायरस से संक्रमित 20,000 से अधिक रो...  [1, 0, 0, 0]  \n",
       "805   पाकिस्तान में शेष बचे हिन्दुओं के लिए भी कोई म...  [1, 0, 0, 0]  \n",
       "4035  रेल मंत्री   ने मुंबई में   की परीक्षा देने वा...  [0, 0, 0, 0]  \n",
       "5008  विराट कोहली को टीम इंडिया से बाहर करने की आवाज...  [0, 0, 0, 0]  \n",
       "3247  हिन्दुत्व की जो नींव मोदीजी ने रखी है. यकीन रख...  [0, 0, 1, 0]  \n",
       "2340  यह ख़बर जो एजेंट मीडिया नहीं चलाएगा । दक्षिण अम...  [1, 0, 0, 0]  \n",
       "3215  दिल्ली: प्रधानमंत्री नरेंद्र मोदी ने पूर्व राष...  [0, 0, 0, 0]  \n",
       "653   जिनका एक बाण समंदर तक को सोख सकता है,  अयोध्या...  [0, 0, 1, 0]  \n",
       "3758  अमेरिकी अंतरिक्ष एजेंसी नासा ने ब्रह्मांड की क...  [0, 0, 0, 0]  \n",
       "1190    : दिल्ली समेत देश के कई हिस्सों में होगी झमा...  [0, 0, 0, 0]  \n",
       "0                                                  Post  [0, 0, 0, 0]  \n",
       "4152  मुगलों ने साम दाम दंड भेद द्वारा हिंदुओं का धर...  [0, 1, 1, 0]  \n",
       "5296    की कॉल रिकॉर्ड से पता चला है कि वे अपने पिता...  [0, 0, 0, 0]  \n",
       "583   असली हीरो की आवाज में  सुनिए \"तेरी मिट्टी में ...  [0, 0, 0, 0]  \n",
       "2563          ये सब साले गली के कुत्ते  से भी बेकार है।  [0, 0, 1, 0]  \n",
       "873    ीरखान उर्फ़ परी खान को जल्द ही Arrest  करें क...  [0, 0, 0, 1]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.334313Z",
     "iopub.status.busy": "2020-12-06T11:30:44.334154Z",
     "iopub.status.idle": "2020-12-06T11:30:44.338478Z",
     "shell.execute_reply": "2020-12-06T11:30:44.337925Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.334292Z"
    }
   },
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.339483Z",
     "iopub.status.busy": "2020-12-06T11:30:44.339254Z",
     "iopub.status.idle": "2020-12-06T11:30:44.343877Z",
     "shell.execute_reply": "2020-12-06T11:30:44.343407Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.339462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.344735Z",
     "iopub.status.busy": "2020-12-06T11:30:44.344587Z",
     "iopub.status.idle": "2020-12-06T11:30:44.352206Z",
     "shell.execute_reply": "2020-12-06T11:30:44.351794Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.344715Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.clean\n",
    "        self.targets = self.data.encodelabels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.353037Z",
     "iopub.status.busy": "2020-12-06T11:30:44.352888Z",
     "iopub.status.idle": "2020-12-06T11:30:44.362946Z",
     "shell.execute_reply": "2020-12-06T11:30:44.362524Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.353017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (5528, 15)\n",
      "TRAIN Dataset: (4422, 15)\n",
      "TEST Dataset: (1106, 15)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_data=train.sample(frac=train_size,random_state=200)\n",
    "test_data=train.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "training_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.363814Z",
     "iopub.status.busy": "2020-12-06T11:30:44.363663Z",
     "iopub.status.idle": "2020-12-06T11:30:44.366642Z",
     "shell.execute_reply": "2020-12-06T11:30:44.366231Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.363795Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.367516Z",
     "iopub.status.busy": "2020-12-06T11:30:44.367362Z",
     "iopub.status.idle": "2020-12-06T11:30:50.464232Z",
     "shell.execute_reply": "2020-12-06T11:30:50.463695Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.367496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(models[model_num])\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.465407Z",
     "iopub.status.busy": "2020-12-06T11:30:50.465243Z",
     "iopub.status.idle": "2020-12-06T11:30:50.468241Z",
     "shell.execute_reply": "2020-12-06T11:30:50.467768Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.465385Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.469100Z",
     "iopub.status.busy": "2020-12-06T11:30:50.468949Z",
     "iopub.status.idle": "2020-12-06T11:30:50.474819Z",
     "shell.execute_reply": "2020-12-06T11:30:50.474359Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.469080Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.475733Z",
     "iopub.status.busy": "2020-12-06T11:30:50.475583Z",
     "iopub.status.idle": "2020-12-06T11:30:50.489087Z",
     "shell.execute_reply": "2020-12-06T11:30:50.488688Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.475714Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "#         if _%50==0:\n",
    "#             print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    final_outputs = np.array(fin_outputs) >=0.5\n",
    "    final = []\n",
    "    final_t = []\n",
    "    final_fine = [[],[],[],[]]\n",
    "    final_fine_t = [[],[],[],[]]\n",
    "    for (i,j) in zip(final_outputs, fin_targets):\n",
    "        output_sum = sum(i)\n",
    "        target_sum = sum(j)\n",
    "        if output_sum == 0:\n",
    "            final.append(0)\n",
    "        else:\n",
    "            final.append(1)\n",
    "        if target_sum == 0:\n",
    "            final_t.append(0)\n",
    "        else:\n",
    "            final_t.append(1)\n",
    "        for p in range(4):\n",
    "            final_fine[p].append(int(i[p]))\n",
    "            final_fine_t[p].append(int(j[p]))\n",
    "    print(\"Coarse:\")\n",
    "    print(classification_report(final, final_t))\n",
    "    for i in range(4):\n",
    "        print(\"Fine\", i)\n",
    "        print(classification_report(final_fine[i], final_fine_t[i]))\n",
    "#     return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.489932Z",
     "iopub.status.busy": "2020-12-06T11:30:50.489775Z",
     "iopub.status.idle": "2020-12-06T11:37:02.339961Z",
     "shell.execute_reply": "2020-12-06T11:37:02.339449Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.489913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/tathagata.raha/miniconda3/envs/fastai/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1764: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "139it [00:32,  4.24it/s]\n",
      "2it [00:00, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3369062840938568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.96it/s]\n",
      "/home/tathagata.raha/miniconda3/envs/fastai/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.70      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53      1106\n",
      "   macro avg       0.50      0.27      0.35      1106\n",
      "weighted avg       1.00      0.53      0.70      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80      1106\n",
      "   macro avg       0.50      0.40      0.44      1106\n",
      "weighted avg       1.00      0.80      0.89      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.93      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:33,  4.18it/s]\n",
      "2it [00:00, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.4448566436767578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.70      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53      1106\n",
      "   macro avg       0.50      0.27      0.35      1106\n",
      "weighted avg       1.00      0.53      0.70      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80      1106\n",
      "   macro avg       0.50      0.40      0.44      1106\n",
      "weighted avg       1.00      0.80      0.89      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.93      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:33,  4.13it/s]\n",
      "2it [00:00, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.5884934067726135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.70it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.55      0.71      1068\n",
      "           1       0.07      0.89      0.12        38\n",
      "\n",
      "    accuracy                           0.56      1106\n",
      "   macro avg       0.53      0.72      0.41      1106\n",
      "weighted avg       0.96      0.56      0.69      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1068\n",
      "           1       0.14      0.82      0.24        38\n",
      "\n",
      "    accuracy                           0.82      1106\n",
      "   macro avg       0.57      0.82      0.57      1106\n",
      "weighted avg       0.96      0.82      0.88      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.93      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:33,  4.10it/s]\n",
      "2it [00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.414557546377182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.65it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.61      0.75       935\n",
      "           1       0.29      0.89      0.44       171\n",
      "\n",
      "    accuracy                           0.65      1106\n",
      "   macro avg       0.63      0.75      0.60      1106\n",
      "weighted avg       0.86      0.65      0.70      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       967\n",
      "           1       0.48      0.77      0.59       139\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.72      0.83      0.76      1106\n",
      "weighted avg       0.90      0.87      0.88      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      1075\n",
      "           1       0.11      0.48      0.18        31\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.55      0.68      0.55      1106\n",
      "weighted avg       0.96      0.87      0.91      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1103\n",
      "           1       0.02      1.00      0.04         3\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.51      0.94      0.49      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.09it/s]\n",
      "2it [00:00, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.08098824322223663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.61it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.65      0.78       873\n",
      "           1       0.41      0.91      0.57       233\n",
      "\n",
      "    accuracy                           0.71      1106\n",
      "   macro avg       0.69      0.78      0.67      1106\n",
      "weighted avg       0.85      0.71      0.73      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       939\n",
      "           1       0.54      0.71      0.61       167\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.74      0.80      0.76      1106\n",
      "weighted avg       0.88      0.86      0.87      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93      1048\n",
      "           1       0.17      0.41      0.24        58\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.57      0.65      0.59      1106\n",
      "weighted avg       0.92      0.87      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      1066\n",
      "           1       0.18      0.60      0.28        40\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.58      0.75      0.61      1106\n",
      "weighted avg       0.95      0.89      0.92      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.07it/s]\n",
      "2it [00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.08873924612998962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.55it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77       703\n",
      "           1       0.61      0.78      0.68       403\n",
      "\n",
      "    accuracy                           0.74      1106\n",
      "   macro avg       0.73      0.75      0.73      1106\n",
      "weighted avg       0.76      0.74      0.74      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       785\n",
      "           1       0.80      0.55      0.66       321\n",
      "\n",
      "    accuracy                           0.83      1106\n",
      "   macro avg       0.82      0.75      0.77      1106\n",
      "weighted avg       0.83      0.83      0.82      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1044\n",
      "           1       0.22      0.50      0.31        62\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.60      0.70      0.62      1106\n",
      "weighted avg       0.93      0.88      0.90      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      1054\n",
      "           1       0.21      0.54      0.31        52\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.59      0.72      0.62      1106\n",
      "weighted avg       0.94      0.89      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.06it/s]\n",
      "2it [00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.299334853887558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.57it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84       731\n",
      "           1       0.66      0.91      0.77       375\n",
      "\n",
      "    accuracy                           0.81      1106\n",
      "   macro avg       0.80      0.83      0.80      1106\n",
      "weighted avg       0.85      0.81      0.82      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       891\n",
      "           1       0.65      0.67      0.66       215\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.78      0.79      0.79      1106\n",
      "weighted avg       0.87      0.87      0.87      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       959\n",
      "           1       0.46      0.43      0.44       147\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.68      0.68      0.68      1106\n",
      "weighted avg       0.85      0.86      0.85      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1011\n",
      "           1       0.40      0.55      0.46        95\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.68      0.73      0.70      1106\n",
      "weighted avg       0.91      0.89      0.90      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.07it/s]\n",
      "2it [00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.11874614655971527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.58it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.80       729\n",
      "           1       0.61      0.84      0.71       377\n",
      "\n",
      "    accuracy                           0.76      1106\n",
      "   macro avg       0.75      0.78      0.75      1106\n",
      "weighted avg       0.80      0.76      0.77      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       853\n",
      "           1       0.69      0.61      0.65       253\n",
      "\n",
      "    accuracy                           0.85      1106\n",
      "   macro avg       0.79      0.76      0.78      1106\n",
      "weighted avg       0.84      0.85      0.85      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1028\n",
      "           1       0.26      0.46      0.33        78\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.61      0.68      0.63      1106\n",
      "weighted avg       0.91      0.87      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1028\n",
      "           1       0.35      0.59      0.44        78\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.66      0.75      0.69      1106\n",
      "weighted avg       0.92      0.89      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.07it/s]\n",
      "2it [00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss:  0.006169774569571018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.59it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.71      0.81       797\n",
      "           1       0.55      0.91      0.68       309\n",
      "\n",
      "    accuracy                           0.76      1106\n",
      "   macro avg       0.75      0.81      0.75      1106\n",
      "weighted avg       0.84      0.76      0.78      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       933\n",
      "           1       0.53      0.68      0.59       173\n",
      "\n",
      "    accuracy                           0.85      1106\n",
      "   macro avg       0.73      0.78      0.75      1106\n",
      "weighted avg       0.87      0.85      0.86      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      1002\n",
      "           1       0.35      0.46      0.40       104\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.64      0.69      0.66      1106\n",
      "weighted avg       0.89      0.87      0.88      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1036\n",
      "           1       0.31      0.59      0.41        70\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.64      0.75      0.67      1106\n",
      "weighted avg       0.93      0.89      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.06it/s]\n",
      "2it [00:00, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss:  0.09804540127515793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.82       739\n",
      "           1       0.63      0.89      0.74       367\n",
      "\n",
      "    accuracy                           0.79      1106\n",
      "   macro avg       0.78      0.81      0.78      1106\n",
      "weighted avg       0.83      0.79      0.80      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       895\n",
      "           1       0.62      0.65      0.63       211\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.77      0.78      0.77      1106\n",
      "weighted avg       0.86      0.86      0.86      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1012\n",
      "           1       0.34      0.50      0.41        94\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.65      0.71      0.67      1106\n",
      "weighted avg       0.90      0.88      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1008\n",
      "           1       0.45      0.60      0.52        98\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.71      0.77      0.73      1106\n",
      "weighted avg       0.91      0.90      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.94      1102\n",
      "           1       0.01      0.25      0.02         4\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.50      0.57      0.48      1106\n",
      "weighted avg       0.99      0.89      0.94      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:02.341202Z",
     "iopub.status.busy": "2020-12-06T11:37:02.341039Z",
     "iopub.status.idle": "2020-12-06T11:37:02.346303Z",
     "shell.execute_reply": "2020-12-06T11:37:02.345781Z",
     "shell.execute_reply.started": "2020-12-06T11:37:02.341180Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:02.347177Z",
     "iopub.status.busy": "2020-12-06T11:37:02.347040Z",
     "iopub.status.idle": "2020-12-06T11:37:05.661360Z",
     "shell.execute_reply": "2020-12-06T11:37:05.660891Z",
     "shell.execute_reply.started": "2020-12-06T11:37:02.347159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.59it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs, targets = validation(testing_loader)\n",
    "\n",
    "final_outputs = np.array(outputs) >=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:05.662164Z",
     "iopub.status.busy": "2020-12-06T11:37:05.662027Z",
     "iopub.status.idle": "2020-12-06T11:37:05.674775Z",
     "shell.execute_reply": "2020-12-06T11:37:05.674307Z",
     "shell.execute_reply.started": "2020-12-06T11:37:05.662146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Score = 0.6835443037974683\n",
      "Hamming Loss = 0.11867088607594936\n"
     ]
    }
   ],
   "source": [
    "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
    "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
    "\n",
    "print(f\"Hamming Score = {val_hamming_score}\")\n",
    "print(f\"Hamming Loss = {val_hamming_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:05.675675Z",
     "iopub.status.busy": "2020-12-06T11:37:05.675502Z",
     "iopub.status.idle": "2020-12-06T11:37:05.715583Z",
     "shell.execute_reply": "2020-12-06T11:37:05.715090Z",
     "shell.execute_reply.started": "2020-12-06T11:37:05.675645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.82       739\n",
      "           1       0.63      0.89      0.74       367\n",
      "\n",
      "    accuracy                           0.79      1106\n",
      "   macro avg       0.78      0.81      0.78      1106\n",
      "weighted avg       0.83      0.79      0.80      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       895\n",
      "           1       0.62      0.65      0.63       211\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.77      0.78      0.77      1106\n",
      "weighted avg       0.86      0.86      0.86      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1012\n",
      "           1       0.34      0.50      0.41        94\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.65      0.71      0.67      1106\n",
      "weighted avg       0.90      0.88      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1008\n",
      "           1       0.45      0.60      0.52        98\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.71      0.77      0.73      1106\n",
      "weighted avg       0.91      0.90      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.94      1102\n",
      "           1       0.01      0.25      0.02         4\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.50      0.57      0.48      1106\n",
      "weighted avg       0.99      0.89      0.94      1106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "total = len(targets)\n",
    "final = []\n",
    "final_t = []\n",
    "final_fine = [[],[],[],[]]\n",
    "final_fine_t = [[],[],[],[]]\n",
    "for (i,j) in zip(final_outputs, targets):\n",
    "    output_sum = sum(i)\n",
    "    target_sum = sum(j)\n",
    "    if output_sum == 0:\n",
    "        final.append(0)\n",
    "    else:\n",
    "        final.append(1)\n",
    "    if target_sum == 0:\n",
    "        final_t.append(0)\n",
    "    else:\n",
    "        final_t.append(1)\n",
    "    for p in range(4):\n",
    "        final_fine[p].append(int(i[p]))\n",
    "        final_fine_t[p].append(int(j[p]))\n",
    "print(\"Coarse:\")\n",
    "print(classification_report(final, final_t))\n",
    "for i in range(4):\n",
    "    print(\"Fine\", i)\n",
    "    print(classification_report(final_fine[i], final_fine_t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:05.716445Z",
     "iopub.status.busy": "2020-12-06T11:37:05.716301Z",
     "iopub.status.idle": "2020-12-06T11:37:06.515742Z",
     "shell.execute_reply": "2020-12-06T11:37:06.515034Z",
     "shell.execute_reply.started": "2020-12-06T11:37:05.716427Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f5a253470e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-06T11:37:06.516304Z",
     "iopub.status.idle": "2020-12-06T11:37:06.516589Z"
    }
   },
   "outputs": [],
   "source": [
    "final_fine = [[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-06T11:37:06.517208Z",
     "iopub.status.idle": "2020-12-06T11:37:06.517499Z"
    }
   },
   "outputs": [],
   "source": [
    "final_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
