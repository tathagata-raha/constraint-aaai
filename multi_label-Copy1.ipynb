{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:34.830113Z",
     "iopub.status.busy": "2020-12-06T11:30:34.829891Z",
     "iopub.status.idle": "2020-12-06T11:30:37.982925Z",
     "shell.execute_reply": "2020-12-06T11:30:37.982361Z",
     "shell.execute_reply.started": "2020-12-06T11:30:34.830068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert code here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm, neighbors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, BertConfig, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# sent_encoder = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:37.984119Z",
     "iopub.status.busy": "2020-12-06T11:30:37.983958Z",
     "iopub.status.idle": "2020-12-06T11:30:38.014648Z",
     "shell.execute_reply": "2020-12-06T11:30:38.014151Z",
     "shell.execute_reply.started": "2020-12-06T11:30:37.984098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda:1\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:38.017684Z",
     "iopub.status.busy": "2020-12-06T11:30:38.017532Z",
     "iopub.status.idle": "2020-12-06T11:30:44.033930Z",
     "shell.execute_reply": "2020-12-06T11:30:44.033138Z",
     "shell.execute_reply.started": "2020-12-06T11:30:38.017664Z"
    }
   },
   "outputs": [],
   "source": [
    "models = ['bert-base-multilingual-cased', 'xlm-roberta-base', 'sagorsarker/bangla-bert-base', 'ai4bharat/indic-bert']\n",
    "model_num = 3\n",
    "tokenizer = AutoTokenizer.from_pretrained(models[model_num])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.035301Z",
     "iopub.status.busy": "2020-12-06T11:30:44.035068Z",
     "iopub.status.idle": "2020-12-06T11:30:44.204446Z",
     "shell.execute_reply": "2020-12-06T11:30:44.203961Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.035216Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train.pickle','rb') as f:\n",
    "    train = pickle.load(f)\n",
    "    train = pd.DataFrame.from_dict(train)\n",
    "with open('valid.pickle','rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    test = pd.DataFrame.from_dict(test)\n",
    "# test = pd.read_csv('data/valid.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.205449Z",
     "iopub.status.busy": "2020-12-06T11:30:44.205285Z",
     "iopub.status.idle": "2020-12-06T11:30:44.260924Z",
     "shell.execute_reply": "2020-12-06T11:30:44.260518Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.205429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>task_1</th>\n",
       "      <th>full_tweet</th>\n",
       "      <th>tweet_raw_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>smiley</th>\n",
       "      <th>emoji</th>\n",
       "      <th>url</th>\n",
       "      <th>mentions</th>\n",
       "      <th>numerals</th>\n",
       "      <th>reserved_word</th>\n",
       "      <th>emotext</th>\n",
       "      <th>segmented_hash</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>4679</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>Poco M2 Pro ‡§Ö‡§¨ ‡§ì‡§™‡§® ‡§∏‡•á‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß, ‡§ú‡§æ‡§®‡•á‡§Ç ‡§¶‡§æ‡§Æ ‡§µ...</td>\n",
       "      <td>Poco M2 Pro ‡§Ö‡§¨ ‡§ì‡§™‡§® ‡§∏‡•á‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ,  ‡§ú‡§æ‡§®‡•á‡§Ç ‡§¶‡§æ‡§Æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/dYMuRBgziu, https://t.co/4nqZTgT...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Poco M2 Pro ‡§Ö‡§¨ ‡§ì‡§™‡§® ‡§∏‡•á‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß, ‡§ú‡§æ‡§®‡•á‡§Ç ‡§¶‡§æ‡§Æ ‡§µ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>5133</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§°‡•â. ‡§ï‡§´‡•Ä‡§≤ ‡§ñ‡§æ‡§® ‡§™‡§∞ ‡§∏‡•á ‡§π‡§ü‡§æ NSA, ‡§á‡§≤‡§æ‡§π‡§æ‡§¨‡§æ‡§¶ HC ‡§®‡•á ‡§¶‡§ø‡§Ø...</td>\n",
       "      <td>‡§°‡•â. ‡§ï‡§´‡•Ä‡§≤ ‡§ñ‡§æ‡§® ‡§™‡§∞ ‡§∏‡•á ‡§π‡§ü‡§æ NSA ,  ‡§á‡§≤‡§æ‡§π‡§æ‡§¨‡§æ‡§¶ HC ‡§®‡•á ‡§¶...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/W5m2FZjYwj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§°‡•â. ‡§ï‡§´‡•Ä‡§≤ ‡§ñ‡§æ‡§® ‡§™‡§∞ ‡§∏‡•á ‡§π‡§ü‡§æ NSA, ‡§á‡§≤‡§æ‡§π‡§æ‡§¨‡§æ‡§¶ HC ‡§®‡•á ‡§¶‡§ø‡§Ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>768</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>20 ‡§∏‡§æ‡§≤ ‡§∏‡•á ‡§ú‡§®‡§§‡§æ ‡§ï‡•á ‡§≠‡§∞‡•ã‡§∏‡•á ‡§™‡§∞ ‡§ï‡§æ‡§Ø‡§Æ ‡§π‡•à ‡§Ü‡§ú‡§§‡§ï‡•§ ‡§ñ‡§¨‡§∞ ‡§Æ...</td>\n",
       "      <td>‡§∏‡§æ‡§≤ ‡§∏‡•á ‡§ú‡§®‡§§‡§æ ‡§ï‡•á ‡§≠‡§∞‡•ã‡§∏‡•á ‡§™‡§∞ ‡§ï‡§æ‡§Ø‡§Æ ‡§π‡•à ‡§Ü‡§ú‡§§‡§ï‡•§ ‡§ñ‡§¨‡§∞ ‡§Æ‡§§‡§≤‡§¨...</td>\n",
       "      <td>[#Promo, #AajTakNo1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/vc6dVdOZs1]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[promo, aaj tak no 1]</td>\n",
       "      <td>20 ‡§∏‡§æ‡§≤ ‡§∏‡•á ‡§ú‡§®‡§§‡§æ ‡§ï‡•á ‡§≠‡§∞‡•ã‡§∏‡•á ‡§™‡§∞ ‡§ï‡§æ‡§Ø‡§Æ ‡§π‡•à ‡§Ü‡§ú‡§§‡§ï‡•§ ‡§ñ‡§¨‡§∞ ‡§Æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3160</th>\n",
       "      <td>3275</td>\n",
       "      <td>defamation</td>\n",
       "      <td>‡§ó‡§ø‡§∞‡•Ä ‡§π‡•Å‡§à ‡§á‡§ï‡•ã‡§®‡•â‡§Æ‡•Ä ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ö‡§æ‡§á‡§®‡§æ ‡§∏‡•ã‡§ö‡•á‡§ó‡§æ, ‡§ê‡§∏‡•Ä ‡§ó‡§ø‡§∞‡•Ä ...</td>\n",
       "      <td>‡§ó‡§ø‡§∞‡•Ä ‡§π‡•Å‡§à ‡§á‡§ï‡•ã‡§®‡•â‡§Æ‡•Ä ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ö‡§æ‡§á‡§®‡§æ ‡§∏‡•ã‡§ö‡•á‡§ó‡§æ ,  ‡§ê‡§∏‡•Ä ‡§ó‡§ø‡§∞...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ó‡§ø‡§∞‡•Ä ‡§π‡•Å‡§à ‡§á‡§ï‡•ã‡§®‡•â‡§Æ‡•Ä ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ö‡§æ‡§á‡§®‡§æ ‡§∏‡•ã‡§ö‡•á‡§ó‡§æ, ‡§ê‡§∏‡•Ä ‡§ó‡§ø‡§∞‡•Ä ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>3260</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‚Äò‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§≠‡§∞‡•ç‡§§‡•Ä ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä‚Äò ‡§™‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≠‡§∞...</td>\n",
       "      <td>‚Äò‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§≠‡§∞‡•ç‡§§‡•Ä ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä‚Äò ‡§™‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≠‡§∞...</td>\n",
       "      <td>[#NTA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/h1QENG8F5V, https://t.co/I9d22U9...</td>\n",
       "      <td>[@DrJitendraSingh]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nta]</td>\n",
       "      <td>‚Äò‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§≠‡§∞‡•ç‡§§‡•Ä ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä‚Äò ‡§™‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≠‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5394</th>\n",
       "      <td>5595</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§ï‡§Ç‡§ó‡§®‡§æ ‡§∏‡•á ‡§µ‡§ø‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ ‡§ï‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü, '‡§Æ‡•á‡§∞...</td>\n",
       "      <td>‡§ï‡§Ç‡§ó‡§®‡§æ ‡§∏‡•á ‡§µ‡§ø‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ ‡§ï‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü ,  '‡§Æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/8Do3QWQ7Fr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ï‡§Ç‡§ó‡§®‡§æ ‡§∏‡•á ‡§µ‡§ø‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ ‡§ï‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü, '‡§Æ‡•á‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>835</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>CM ‡§†‡§æ‡§ï‡•Å‡§∞ ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ï‡§ø 9 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§ï‡•Ä ‡§Æ‡•Å‡§Ç‡§¨...</td>\n",
       "      <td>CM ‡§†‡§æ‡§ï‡•Å‡§∞ ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ï‡§ø ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§ï‡•Ä ‡§Æ‡•Å‡§Ç‡§¨‡§à ...</td>\n",
       "      <td>[#KanganaRanaut, #HimachalPradesh]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/NHJnhKf8Ba]</td>\n",
       "      <td>[@satenderchauhan]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[kangana ranaut, himachal pradesh]</td>\n",
       "      <td>CM ‡§†‡§æ‡§ï‡•Å‡§∞ ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ï‡§ø 9 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§ï‡•Ä ‡§Æ‡•Å‡§Ç‡§¨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>1259</td>\n",
       "      <td>fake</td>\n",
       "      <td>*#‡§ú‡§Ø‡§™‡•Å‡§∞ ‡§ï‡§æ #‡§∞‡§æ‡§ú-‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞ #‡§∏‡§ø‡§®‡•á‡§Æ‡§æ‡§π‡•â‡§≤ ‡§¨‡§ø‡§ï‡§æ...#*  *...</td>\n",
       "      <td>*#‡§ú‡§Ø‡§™‡•Å‡§∞ ‡§ï‡§æ #‡§∞‡§æ‡§ú-‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞ #‡§∏‡§ø‡§®‡•á‡§Æ‡§æ‡§π‡•â‡§≤ ‡§¨‡§ø‡§ï‡§æ...#*  *...</td>\n",
       "      <td>[#‡§ú‡§Ø‡§™, #‡§∞, #‡§∏, #, #‡§™, #, #‡§è‡§∂, #, #‡§∞, #]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 30]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[‡§ú‡§Ø‡§™, ‡§∞, ‡§∏, , ‡§™, , ‡§è‡§∂, , ‡§∞, ]</td>\n",
       "      <td>* ‡•Å‡§∞ ‡§ï‡§æ  ‡§æ‡§ú-‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞  ‡§ø‡§®‡•á‡§Æ‡§æ‡§π‡•â‡§≤ ‡§¨‡§ø‡§ï‡§æ... *  * ‡§™‡•ç‡§∞‡§æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1019</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>....‡§∏‡•á ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡§ø‡§§ ‡§™‡§∞‡§æ‡§∏‡•ç‡§®‡§æ‡§§‡§ï ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§§...</td>\n",
       "      <td>....‡§∏‡•á ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡§ø‡§§ ‡§™‡§∞‡§æ‡§∏‡•ç‡§®‡§æ‡§§‡§ï ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§§...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@AwasthiAwanishK]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>....‡§∏‡•á ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡§ø‡§§ ‡§™‡§∞‡§æ‡§∏‡•ç‡§®‡§æ‡§§‡§ï ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>1704</td>\n",
       "      <td>defamation,hate,offensive</td>\n",
       "      <td>@Samrehman03 .@Samrehman03  ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§ï‡§Æ‡•Ä‡§®‡§æ ‡§π‡•à...</td>\n",
       "      <td>.@Samrehman03  ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§ï‡§Æ‡•Ä‡§®‡§æ ‡§π‡•à ‡§Ø‡•á ,  ‡§∏‡§ø‡§∞‡•ç‡§´ ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[üôÑ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@Samrehman03, @Samrehman03]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[face with rolling eyes]</td>\n",
       "      <td>[]</td>\n",
       "      <td>.   ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§ï‡§Æ‡•Ä‡§®‡§æ ‡§π‡•à ‡§Ø‡•á, ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1415</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§ï‡•Å‡§∂‡•Ä‡§®‡§ó‡§∞ ‡§∏‡•á ‡§¶‡•ã ‡§Æ‡§æ‡§π ‡§Æ‡•á‡§Ç ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§â‡§°‡§º‡§æ‡§®: ‡§Æ‡•Å‡§ñ...</td>\n",
       "      <td>‡§ï‡•Å‡§∂‡•Ä‡§®‡§ó‡§∞ ‡§∏‡•á ‡§¶‡•ã ‡§Æ‡§æ‡§π ‡§Æ‡•á‡§Ç ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§â‡§°‡§º‡§æ‡§® :  ‡§Æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/RszRfoKFXG]</td>\n",
       "      <td>[@myogiadityanath]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ï‡•Å‡§∂‡•Ä‡§®‡§ó‡§∞ ‡§∏‡•á ‡§¶‡•ã ‡§Æ‡§æ‡§π ‡§Æ‡•á‡§Ç ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§â‡§°‡§º‡§æ‡§®: ‡§Æ‡•Å‡§ñ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>5658</td>\n",
       "      <td>defamation</td>\n",
       "      <td>‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§®‡•Ä ‡§∏‡•á‡§®‡§æ ‡§®‡•á ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•á‡§®‡§æ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§à‡§¶ ‡§™‡§∞ ‡§≠‡•á...</td>\n",
       "      <td>‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§®‡•Ä ‡§∏‡•á‡§®‡§æ ‡§®‡•á ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•á‡§®‡§æ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§à‡§¶ ‡§™‡§∞ ‡§≠‡•á...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§®‡•Ä ‡§∏‡•á‡§®‡§æ ‡§®‡•á ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•á‡§®‡§æ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§à‡§¶ ‡§™‡§∞ ‡§≠‡•á...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>3584</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§µ‡§∞‡§ø‡§∑‡•ç‡§† ‡§µ‡§ï‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§∂‡§æ‡§Ç‡§§ ‡§≠‡•Ç‡§∑‡§£ ‡§¨‡•ã‡§≤‡•á, ‡§Æ‡•á‡§∞‡•á ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏ ‡§ï‡§æ...</td>\n",
       "      <td>‡§µ‡§∞‡§ø‡§∑‡•ç‡§† ‡§µ‡§ï‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§∂‡§æ‡§Ç‡§§ ‡§≠‡•Ç‡§∑‡§£ ‡§¨‡•ã‡§≤‡•á ,  ‡§Æ‡•á‡§∞‡•á ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏ ...</td>\n",
       "      <td>[#PrashantBhushanCase, #SupremeCourt]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/fSXXQsF3yg]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[prashant bhushan case, supreme court]</td>\n",
       "      <td>‡§µ‡§∞‡§ø‡§∑‡•ç‡§† ‡§µ‡§ï‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§∂‡§æ‡§Ç‡§§ ‡§≠‡•Ç‡§∑‡§£ ‡§¨‡•ã‡§≤‡•á, ‡§Æ‡•á‡§∞‡•á ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏ ‡§ï‡§æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4487</th>\n",
       "      <td>4602</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§Ø‡•á ‡§ê‡§∏‡§æ ‡§∏‡•á‡§≤‡•ç‡§´‡§º‡•Ä ‡§ï‡•à‡§Æ‡§∞‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§§‡•ã ‡§π‡•à, ‡§Æ‡§ó‡§∞ ‡§¶...</td>\n",
       "      <td>‡§Ø‡•á ‡§ê‡§∏‡§æ ‡§∏‡•á‡§≤‡•ç‡§´‡§º‡•Ä ‡§ï‡•à‡§Æ‡§∞‡§æ ‡§π‡•à ,  ‡§ú‡•ã ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§§‡•ã ‡§π‡•à ,  ‡§Æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/qOl0fcBCIC]</td>\n",
       "      <td>[@itsmeFSL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ø‡•á ‡§ê‡§∏‡§æ ‡§∏‡•á‡§≤‡•ç‡§´‡§º‡•Ä ‡§ï‡•à‡§Æ‡§∞‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§§‡•ã ‡§π‡•à, ‡§Æ‡§ó‡§∞ ‡§¶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>4120</td>\n",
       "      <td>fake</td>\n",
       "      <td>‡§ö‡•Ä‡§® ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§∞ ‡§ï‡§ø‡§Æ‡•Ä ‡§Ö‡§Ç‡§¶‡§∞ ‡§ò‡•Å‡§∏ ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à‡§Ç ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∏‡•á‡§®...</td>\n",
       "      <td>‡§ö‡•Ä‡§® ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§∞ ‡§ï‡§ø‡§Æ‡•Ä ‡§Ö‡§Ç‡§¶‡§∞ ‡§ò‡•Å‡§∏ ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à‡§Ç ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∏‡•á‡§®...</td>\n",
       "      <td>[#ModiHaiToMumkinHai]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@INCIndia, @ippatel]</td>\n",
       "      <td>[1962, 57]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[modi hai to mumkin hai]</td>\n",
       "      <td>‡§ö‡•Ä‡§® ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§∞ ‡§ï‡§ø‡§Æ‡•Ä ‡§Ö‡§Ç‡§¶‡§∞ ‡§ò‡•Å‡§∏ ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à‡§Ç ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∏‡•á‡§®...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>3988</td>\n",
       "      <td>hate</td>\n",
       "      <td>‡§ß‡•Ç‡§≤ ‡§ö‡§ü‡§æ ‡§¶‡•ã ‡§ó‡§ø‡§¶‡•ç‡§ß‡•ã‡§Ç ‡§ï‡•ã ,‡§ú‡•ã ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏ ‡§ï‡§∞ ‡§ò‡§æ‡§§ ‡§ï‡§∞...</td>\n",
       "      <td>‡§ß‡•Ç‡§≤ ‡§ö‡§ü‡§æ ‡§¶‡•ã ‡§ó‡§ø‡§¶‡•ç‡§ß‡•ã‡§Ç ‡§ï‡•ã  , ‡§ú‡•ã ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏ ‡§ï‡§∞ ‡§ò‡§æ‡§§ ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[üö©, üö©, üôè]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[triangular flag, triangular flag, folded hands]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ß‡•Ç‡§≤ ‡§ö‡§ü‡§æ ‡§¶‡•ã ‡§ó‡§ø‡§¶‡•ç‡§ß‡•ã‡§Ç ‡§ï‡•ã ,‡§ú‡•ã ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏ ‡§ï‡§∞ ‡§ò‡§æ‡§§ ‡§ï‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>261</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§¨‡•à‡§Ç‡§ï‡§ø‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡•à‡§Ç‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡•Å‡§≤ ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§ï...</td>\n",
       "      <td>‡§¨‡•à‡§Ç‡§ï‡§ø‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡•à‡§Ç‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡•Å‡§≤ ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§ï...</td>\n",
       "      <td>[#HindiNews]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/AvWQ7l7kA8]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[hindi news]</td>\n",
       "      <td>‡§¨‡•à‡§Ç‡§ï‡§ø‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡•à‡§Ç‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡•Å‡§≤ ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§ï...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>1684</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@JayHind11544289 ‡§ú‡§Ø ‡§π‡§ø‡§®‡•ç‡§¶ ‡§ï‡•Ä ‡§∏‡•á‡§®‡§æ..üëåüëèüëèüëç ‡§î‡§∞ ‡§ú‡•ã ...</td>\n",
       "      <td>‡§ú‡§Ø ‡§π‡§ø‡§®‡•ç‡§¶ ‡§ï‡•Ä ‡§∏‡•á‡§®‡§æ..üëåüëèüëèüëç ‡§î‡§∞ ‡§ú‡•ã ‡§®‡§æ‡§≤‡§æ‡§Ø‡§ï ‡§¶‡•á‡§∂ ‡§¶‡•ç‡§∞‡•ã‡§π‡•Ä...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[üëå, üëè, üëè, üëç, üò†, üò†]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@JayHind11544289]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[OK hand, clapping hands, clapping hands, thum...</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ú‡§Ø ‡§π‡§ø‡§®‡•ç‡§¶ ‡§ï‡•Ä ‡§∏‡•á‡§®‡§æ..     ‡§î‡§∞ ‡§ú‡•ã ‡§®‡§æ‡§≤‡§æ‡§Ø‡§ï ‡§¶‡•á‡§∂ ‡§¶‡•ç‡§∞‡•ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>4843</td>\n",
       "      <td>defamation</td>\n",
       "      <td>‡§Ø‡•á ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§µ‡§æ‡§≤‡•á, ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡§¶ ‡§µ‡§æ‡§≤‡§æ ‡§°‡•ç‡§∞‡§æ‡§Æ‡§æ ‡§∏‡§Æ‡§Ø  ...</td>\n",
       "      <td>‡§Ø‡•á ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§µ‡§æ‡§≤‡•á ,  ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡§¶ ‡§µ‡§æ‡§≤‡§æ ‡§°‡•ç‡§∞‡§æ‡§Æ‡§æ ‡§∏‡§Æ‡§Ø...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[üòÇ, üòÇ, üòÇ, üòú, üòú, üòú]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[face with tears of joy, face with tears of jo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ø‡•á ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§µ‡§æ‡§≤‡•á, ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡§¶ ‡§µ‡§æ‡§≤‡§æ ‡§°‡•ç‡§∞‡§æ‡§Æ‡§æ ‡§∏‡§Æ‡§Ø  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2134</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§è‡§ï ‡§î‡§∞ ‡§™‡§π‡§≤ https://t.co/lOuMTPDfXr</td>\n",
       "      <td>‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§è‡§ï ‡§î‡§∞ ‡§™‡§π‡§≤ https : //t.co/lOuMTP...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/lOuMTPDfXr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§è‡§ï ‡§î‡§∞ ‡§™‡§π‡§≤</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id                     task_1  \\\n",
       "4564     4679                non-hostile   \n",
       "4932     5133                non-hostile   \n",
       "768       768                non-hostile   \n",
       "3160     3275                 defamation   \n",
       "3145     3260                non-hostile   \n",
       "5394     5595                non-hostile   \n",
       "835       835                non-hostile   \n",
       "1192     1259                       fake   \n",
       "1019     1019                non-hostile   \n",
       "1637     1704  defamation,hate,offensive   \n",
       "1348     1415                non-hostile   \n",
       "5457     5658                 defamation   \n",
       "3469     3584                non-hostile   \n",
       "4487     4602                non-hostile   \n",
       "4005     4120                       fake   \n",
       "3873     3988                       hate   \n",
       "261       261                non-hostile   \n",
       "1617     1684                  offensive   \n",
       "4728     4843                 defamation   \n",
       "2067     2134                non-hostile   \n",
       "\n",
       "                                             full_tweet  \\\n",
       "4564  Poco M2 Pro ‡§Ö‡§¨ ‡§ì‡§™‡§® ‡§∏‡•á‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß, ‡§ú‡§æ‡§®‡•á‡§Ç ‡§¶‡§æ‡§Æ ‡§µ...   \n",
       "4932  ‡§°‡•â. ‡§ï‡§´‡•Ä‡§≤ ‡§ñ‡§æ‡§® ‡§™‡§∞ ‡§∏‡•á ‡§π‡§ü‡§æ NSA, ‡§á‡§≤‡§æ‡§π‡§æ‡§¨‡§æ‡§¶ HC ‡§®‡•á ‡§¶‡§ø‡§Ø...   \n",
       "768   20 ‡§∏‡§æ‡§≤ ‡§∏‡•á ‡§ú‡§®‡§§‡§æ ‡§ï‡•á ‡§≠‡§∞‡•ã‡§∏‡•á ‡§™‡§∞ ‡§ï‡§æ‡§Ø‡§Æ ‡§π‡•à ‡§Ü‡§ú‡§§‡§ï‡•§ ‡§ñ‡§¨‡§∞ ‡§Æ...   \n",
       "3160  ‡§ó‡§ø‡§∞‡•Ä ‡§π‡•Å‡§à ‡§á‡§ï‡•ã‡§®‡•â‡§Æ‡•Ä ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ö‡§æ‡§á‡§®‡§æ ‡§∏‡•ã‡§ö‡•á‡§ó‡§æ, ‡§ê‡§∏‡•Ä ‡§ó‡§ø‡§∞‡•Ä ...   \n",
       "3145  ‚Äò‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§≠‡§∞‡•ç‡§§‡•Ä ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä‚Äò ‡§™‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≠‡§∞...   \n",
       "5394  ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§∏‡•á ‡§µ‡§ø‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ ‡§ï‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü, '‡§Æ‡•á‡§∞...   \n",
       "835   CM ‡§†‡§æ‡§ï‡•Å‡§∞ ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ï‡§ø 9 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§ï‡•Ä ‡§Æ‡•Å‡§Ç‡§¨...   \n",
       "1192  *#‡§ú‡§Ø‡§™‡•Å‡§∞ ‡§ï‡§æ #‡§∞‡§æ‡§ú-‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞ #‡§∏‡§ø‡§®‡•á‡§Æ‡§æ‡§π‡•â‡§≤ ‡§¨‡§ø‡§ï‡§æ...#*  *...   \n",
       "1019  ....‡§∏‡•á ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡§ø‡§§ ‡§™‡§∞‡§æ‡§∏‡•ç‡§®‡§æ‡§§‡§ï ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§§...   \n",
       "1637  @Samrehman03 .@Samrehman03  ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§ï‡§Æ‡•Ä‡§®‡§æ ‡§π‡•à...   \n",
       "1348  ‡§ï‡•Å‡§∂‡•Ä‡§®‡§ó‡§∞ ‡§∏‡•á ‡§¶‡•ã ‡§Æ‡§æ‡§π ‡§Æ‡•á‡§Ç ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§â‡§°‡§º‡§æ‡§®: ‡§Æ‡•Å‡§ñ...   \n",
       "5457  ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§®‡•Ä ‡§∏‡•á‡§®‡§æ ‡§®‡•á ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•á‡§®‡§æ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§à‡§¶ ‡§™‡§∞ ‡§≠‡•á...   \n",
       "3469  ‡§µ‡§∞‡§ø‡§∑‡•ç‡§† ‡§µ‡§ï‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§∂‡§æ‡§Ç‡§§ ‡§≠‡•Ç‡§∑‡§£ ‡§¨‡•ã‡§≤‡•á, ‡§Æ‡•á‡§∞‡•á ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏ ‡§ï‡§æ...   \n",
       "4487  ‡§Ø‡•á ‡§ê‡§∏‡§æ ‡§∏‡•á‡§≤‡•ç‡§´‡§º‡•Ä ‡§ï‡•à‡§Æ‡§∞‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§§‡•ã ‡§π‡•à, ‡§Æ‡§ó‡§∞ ‡§¶...   \n",
       "4005  ‡§ö‡•Ä‡§® ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§∞ ‡§ï‡§ø‡§Æ‡•Ä ‡§Ö‡§Ç‡§¶‡§∞ ‡§ò‡•Å‡§∏ ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à‡§Ç ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∏‡•á‡§®...   \n",
       "3873  ‡§ß‡•Ç‡§≤ ‡§ö‡§ü‡§æ ‡§¶‡•ã ‡§ó‡§ø‡§¶‡•ç‡§ß‡•ã‡§Ç ‡§ï‡•ã ,‡§ú‡•ã ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏ ‡§ï‡§∞ ‡§ò‡§æ‡§§ ‡§ï‡§∞...   \n",
       "261   ‡§¨‡•à‡§Ç‡§ï‡§ø‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡•à‡§Ç‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡•Å‡§≤ ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§ï...   \n",
       "1617  @JayHind11544289 ‡§ú‡§Ø ‡§π‡§ø‡§®‡•ç‡§¶ ‡§ï‡•Ä ‡§∏‡•á‡§®‡§æ..üëåüëèüëèüëç ‡§î‡§∞ ‡§ú‡•ã ...   \n",
       "4728  ‡§Ø‡•á ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§µ‡§æ‡§≤‡•á, ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡§¶ ‡§µ‡§æ‡§≤‡§æ ‡§°‡•ç‡§∞‡§æ‡§Æ‡§æ ‡§∏‡§Æ‡§Ø  ...   \n",
       "2067   ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§è‡§ï ‡§î‡§∞ ‡§™‡§π‡§≤ https://t.co/lOuMTPDfXr   \n",
       "\n",
       "                                         tweet_raw_text  \\\n",
       "4564  Poco M2 Pro ‡§Ö‡§¨ ‡§ì‡§™‡§® ‡§∏‡•á‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ,  ‡§ú‡§æ‡§®‡•á‡§Ç ‡§¶‡§æ‡§Æ...   \n",
       "4932  ‡§°‡•â. ‡§ï‡§´‡•Ä‡§≤ ‡§ñ‡§æ‡§® ‡§™‡§∞ ‡§∏‡•á ‡§π‡§ü‡§æ NSA ,  ‡§á‡§≤‡§æ‡§π‡§æ‡§¨‡§æ‡§¶ HC ‡§®‡•á ‡§¶...   \n",
       "768   ‡§∏‡§æ‡§≤ ‡§∏‡•á ‡§ú‡§®‡§§‡§æ ‡§ï‡•á ‡§≠‡§∞‡•ã‡§∏‡•á ‡§™‡§∞ ‡§ï‡§æ‡§Ø‡§Æ ‡§π‡•à ‡§Ü‡§ú‡§§‡§ï‡•§ ‡§ñ‡§¨‡§∞ ‡§Æ‡§§‡§≤‡§¨...   \n",
       "3160  ‡§ó‡§ø‡§∞‡•Ä ‡§π‡•Å‡§à ‡§á‡§ï‡•ã‡§®‡•â‡§Æ‡•Ä ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ö‡§æ‡§á‡§®‡§æ ‡§∏‡•ã‡§ö‡•á‡§ó‡§æ ,  ‡§ê‡§∏‡•Ä ‡§ó‡§ø‡§∞...   \n",
       "3145  ‚Äò‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§≠‡§∞‡•ç‡§§‡•Ä ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä‚Äò ‡§™‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≠‡§∞...   \n",
       "5394  ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§∏‡•á ‡§µ‡§ø‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ ‡§ï‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü ,  '‡§Æ...   \n",
       "835   CM ‡§†‡§æ‡§ï‡•Å‡§∞ ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ï‡§ø ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§ï‡•Ä ‡§Æ‡•Å‡§Ç‡§¨‡§à ...   \n",
       "1192  *#‡§ú‡§Ø‡§™‡•Å‡§∞ ‡§ï‡§æ #‡§∞‡§æ‡§ú-‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞ #‡§∏‡§ø‡§®‡•á‡§Æ‡§æ‡§π‡•â‡§≤ ‡§¨‡§ø‡§ï‡§æ...#*  *...   \n",
       "1019  ....‡§∏‡•á ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡§ø‡§§ ‡§™‡§∞‡§æ‡§∏‡•ç‡§®‡§æ‡§§‡§ï ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§§...   \n",
       "1637  .@Samrehman03  ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§ï‡§Æ‡•Ä‡§®‡§æ ‡§π‡•à ‡§Ø‡•á ,  ‡§∏‡§ø‡§∞‡•ç‡§´ ...   \n",
       "1348  ‡§ï‡•Å‡§∂‡•Ä‡§®‡§ó‡§∞ ‡§∏‡•á ‡§¶‡•ã ‡§Æ‡§æ‡§π ‡§Æ‡•á‡§Ç ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§â‡§°‡§º‡§æ‡§® :  ‡§Æ...   \n",
       "5457  ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§®‡•Ä ‡§∏‡•á‡§®‡§æ ‡§®‡•á ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•á‡§®‡§æ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§à‡§¶ ‡§™‡§∞ ‡§≠‡•á...   \n",
       "3469  ‡§µ‡§∞‡§ø‡§∑‡•ç‡§† ‡§µ‡§ï‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§∂‡§æ‡§Ç‡§§ ‡§≠‡•Ç‡§∑‡§£ ‡§¨‡•ã‡§≤‡•á ,  ‡§Æ‡•á‡§∞‡•á ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏ ...   \n",
       "4487  ‡§Ø‡•á ‡§ê‡§∏‡§æ ‡§∏‡•á‡§≤‡•ç‡§´‡§º‡•Ä ‡§ï‡•à‡§Æ‡§∞‡§æ ‡§π‡•à ,  ‡§ú‡•ã ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§§‡•ã ‡§π‡•à ,  ‡§Æ...   \n",
       "4005  ‡§ö‡•Ä‡§® ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§∞ ‡§ï‡§ø‡§Æ‡•Ä ‡§Ö‡§Ç‡§¶‡§∞ ‡§ò‡•Å‡§∏ ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à‡§Ç ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∏‡•á‡§®...   \n",
       "3873  ‡§ß‡•Ç‡§≤ ‡§ö‡§ü‡§æ ‡§¶‡•ã ‡§ó‡§ø‡§¶‡•ç‡§ß‡•ã‡§Ç ‡§ï‡•ã  , ‡§ú‡•ã ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏ ‡§ï‡§∞ ‡§ò‡§æ‡§§ ...   \n",
       "261   ‡§¨‡•à‡§Ç‡§ï‡§ø‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡•à‡§Ç‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡•Å‡§≤ ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§ï...   \n",
       "1617  ‡§ú‡§Ø ‡§π‡§ø‡§®‡•ç‡§¶ ‡§ï‡•Ä ‡§∏‡•á‡§®‡§æ..üëåüëèüëèüëç ‡§î‡§∞ ‡§ú‡•ã ‡§®‡§æ‡§≤‡§æ‡§Ø‡§ï ‡§¶‡•á‡§∂ ‡§¶‡•ç‡§∞‡•ã‡§π‡•Ä...   \n",
       "4728  ‡§Ø‡•á ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§µ‡§æ‡§≤‡•á ,  ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡§¶ ‡§µ‡§æ‡§≤‡§æ ‡§°‡•ç‡§∞‡§æ‡§Æ‡§æ ‡§∏‡§Æ‡§Ø...   \n",
       "2067  ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§è‡§ï ‡§î‡§∞ ‡§™‡§π‡§≤ https : //t.co/lOuMTP...   \n",
       "\n",
       "                                     hashtags smiley               emoji  \\\n",
       "4564                                       []     []                  []   \n",
       "4932                                       []     []                  []   \n",
       "768                      [#Promo, #AajTakNo1]     []                  []   \n",
       "3160                                       []     []                  []   \n",
       "3145                                   [#NTA]     []                  []   \n",
       "5394                                       []     []                  []   \n",
       "835        [#KanganaRanaut, #HimachalPradesh]     []                  []   \n",
       "1192  [#‡§ú‡§Ø‡§™, #‡§∞, #‡§∏, #, #‡§™, #, #‡§è‡§∂, #, #‡§∞, #]     []                  []   \n",
       "1019                                       []     []                  []   \n",
       "1637                                       []     []                 [üôÑ]   \n",
       "1348                                       []     []                  []   \n",
       "5457                                       []     []                  []   \n",
       "3469    [#PrashantBhushanCase, #SupremeCourt]     []                  []   \n",
       "4487                                       []     []                  []   \n",
       "4005                    [#ModiHaiToMumkinHai]     []                  []   \n",
       "3873                                       []     []           [üö©, üö©, üôè]   \n",
       "261                              [#HindiNews]     []                  []   \n",
       "1617                                       []     []  [üëå, üëè, üëè, üëç, üò†, üò†]   \n",
       "4728                                       []     []  [üòÇ, üòÇ, üòÇ, üòú, üòú, üòú]   \n",
       "2067                                       []     []                  []   \n",
       "\n",
       "                                                    url  \\\n",
       "4564  [https://t.co/dYMuRBgziu, https://t.co/4nqZTgT...   \n",
       "4932                          [https://t.co/W5m2FZjYwj]   \n",
       "768                           [https://t.co/vc6dVdOZs1]   \n",
       "3160                                                 []   \n",
       "3145  [https://t.co/h1QENG8F5V, https://t.co/I9d22U9...   \n",
       "5394                          [https://t.co/8Do3QWQ7Fr]   \n",
       "835                           [https://t.co/NHJnhKf8Ba]   \n",
       "1192                                                 []   \n",
       "1019                                                 []   \n",
       "1637                                                 []   \n",
       "1348                          [https://t.co/RszRfoKFXG]   \n",
       "5457                                                 []   \n",
       "3469                          [https://t.co/fSXXQsF3yg]   \n",
       "4487                          [https://t.co/qOl0fcBCIC]   \n",
       "4005                                                 []   \n",
       "3873                                                 []   \n",
       "261                           [https://t.co/AvWQ7l7kA8]   \n",
       "1617                                                 []   \n",
       "4728                                                 []   \n",
       "2067                          [https://t.co/lOuMTPDfXr]   \n",
       "\n",
       "                          mentions    numerals reserved_word  \\\n",
       "4564                            []          []            []   \n",
       "4932                            []          []            []   \n",
       "768                             []        [20]            []   \n",
       "3160                            []          []            []   \n",
       "3145            [@DrJitendraSingh]          []            []   \n",
       "5394                            []          []            []   \n",
       "835             [@satenderchauhan]         [9]            []   \n",
       "1192                            []     [1, 30]            []   \n",
       "1019            [@AwasthiAwanishK]          []            []   \n",
       "1637  [@Samrehman03, @Samrehman03]          []            []   \n",
       "1348            [@myogiadityanath]          []            []   \n",
       "5457                            []          []            []   \n",
       "3469                            []          []            []   \n",
       "4487                   [@itsmeFSL]          []            []   \n",
       "4005         [@INCIndia, @ippatel]  [1962, 57]            []   \n",
       "3873                            []          []            []   \n",
       "261                             []       [100]            []   \n",
       "1617            [@JayHind11544289]          []            []   \n",
       "4728                            []          []            []   \n",
       "2067                            []          []            []   \n",
       "\n",
       "                                                emotext  \\\n",
       "4564                                                 []   \n",
       "4932                                                 []   \n",
       "768                                                  []   \n",
       "3160                                                 []   \n",
       "3145                                                 []   \n",
       "5394                                                 []   \n",
       "835                                                  []   \n",
       "1192                                                 []   \n",
       "1019                                                 []   \n",
       "1637                           [face with rolling eyes]   \n",
       "1348                                                 []   \n",
       "5457                                                 []   \n",
       "3469                                                 []   \n",
       "4487                                                 []   \n",
       "4005                                                 []   \n",
       "3873   [triangular flag, triangular flag, folded hands]   \n",
       "261                                                  []   \n",
       "1617  [OK hand, clapping hands, clapping hands, thum...   \n",
       "4728  [face with tears of joy, face with tears of jo...   \n",
       "2067                                                 []   \n",
       "\n",
       "                              segmented_hash  \\\n",
       "4564                                      []   \n",
       "4932                                      []   \n",
       "768                    [promo, aaj tak no 1]   \n",
       "3160                                      []   \n",
       "3145                                   [nta]   \n",
       "5394                                      []   \n",
       "835       [kangana ranaut, himachal pradesh]   \n",
       "1192           [‡§ú‡§Ø‡§™, ‡§∞, ‡§∏, , ‡§™, , ‡§è‡§∂, , ‡§∞, ]   \n",
       "1019                                      []   \n",
       "1637                                      []   \n",
       "1348                                      []   \n",
       "5457                                      []   \n",
       "3469  [prashant bhushan case, supreme court]   \n",
       "4487                                      []   \n",
       "4005                [modi hai to mumkin hai]   \n",
       "3873                                      []   \n",
       "261                             [hindi news]   \n",
       "1617                                      []   \n",
       "4728                                      []   \n",
       "2067                                      []   \n",
       "\n",
       "                                                  clean  \n",
       "4564  Poco M2 Pro ‡§Ö‡§¨ ‡§ì‡§™‡§® ‡§∏‡•á‡§≤ ‡§Æ‡•á‡§Ç ‡§â‡§™‡§≤‡§¨‡•ç‡§ß, ‡§ú‡§æ‡§®‡•á‡§Ç ‡§¶‡§æ‡§Æ ‡§µ...  \n",
       "4932  ‡§°‡•â. ‡§ï‡§´‡•Ä‡§≤ ‡§ñ‡§æ‡§® ‡§™‡§∞ ‡§∏‡•á ‡§π‡§ü‡§æ NSA, ‡§á‡§≤‡§æ‡§π‡§æ‡§¨‡§æ‡§¶ HC ‡§®‡•á ‡§¶‡§ø‡§Ø...  \n",
       "768   20 ‡§∏‡§æ‡§≤ ‡§∏‡•á ‡§ú‡§®‡§§‡§æ ‡§ï‡•á ‡§≠‡§∞‡•ã‡§∏‡•á ‡§™‡§∞ ‡§ï‡§æ‡§Ø‡§Æ ‡§π‡•à ‡§Ü‡§ú‡§§‡§ï‡•§ ‡§ñ‡§¨‡§∞ ‡§Æ...  \n",
       "3160  ‡§ó‡§ø‡§∞‡•Ä ‡§π‡•Å‡§à ‡§á‡§ï‡•ã‡§®‡•â‡§Æ‡•Ä ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ö‡§æ‡§á‡§®‡§æ ‡§∏‡•ã‡§ö‡•á‡§ó‡§æ, ‡§ê‡§∏‡•Ä ‡§ó‡§ø‡§∞‡•Ä ...  \n",
       "3145  ‚Äò‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§≠‡§∞‡•ç‡§§‡•Ä ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä‚Äò ‡§™‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≠‡§∞...  \n",
       "5394  ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§∏‡•á ‡§µ‡§ø‡§µ‡§æ‡§¶ ‡§ï‡•á ‡§¨‡•Ä‡§ö ‡§∏‡§Ç‡§ú‡§Ø ‡§∞‡§æ‡§â‡§§ ‡§ï‡§æ ‡§ü‡•ç‡§µ‡•Ä‡§ü, '‡§Æ‡•á‡§∞...  \n",
       "835   CM ‡§†‡§æ‡§ï‡•Å‡§∞ ‡§®‡•á ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ï‡§ø 9 ‡§∏‡§ø‡§§‡§Ç‡§¨‡§∞ ‡§ï‡•ã ‡§ï‡§Ç‡§ó‡§®‡§æ ‡§ï‡•Ä ‡§Æ‡•Å‡§Ç‡§¨...  \n",
       "1192  * ‡•Å‡§∞ ‡§ï‡§æ  ‡§æ‡§ú-‡§Æ‡§®‡•ç‡§¶‡§ø‡§∞  ‡§ø‡§®‡•á‡§Æ‡§æ‡§π‡•â‡§≤ ‡§¨‡§ø‡§ï‡§æ... *  * ‡§™‡•ç‡§∞‡§æ...  \n",
       "1019  ....‡§∏‡•á ‡§∏‡§Æ‡•ç‡§¨‡§®‡•ç‡§ß‡§ø‡§§ ‡§™‡§∞‡§æ‡§∏‡•ç‡§®‡§æ‡§§‡§ï ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§Ö‡§®‡•Å‡§Æ‡§§...  \n",
       "1637    .   ‡§¨‡§π‡•Å‡§§ ‡§¨‡§°‡§º‡§æ ‡§ï‡§Æ‡•Ä‡§®‡§æ ‡§π‡•à ‡§Ø‡•á, ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ç ‡§≠‡§æ‡§á‡§Ø...  \n",
       "1348  ‡§ï‡•Å‡§∂‡•Ä‡§®‡§ó‡§∞ ‡§∏‡•á ‡§¶‡•ã ‡§Æ‡§æ‡§π ‡§Æ‡•á‡§Ç ‡§Ö‡§Ç‡§§‡§∞‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞‡•Ä‡§Ø ‡§â‡§°‡§º‡§æ‡§®: ‡§Æ‡•Å‡§ñ...  \n",
       "5457  ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§®‡•Ä ‡§∏‡•á‡§®‡§æ ‡§®‡•á ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∏‡•á‡§®‡§æ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§à‡§¶ ‡§™‡§∞ ‡§≠‡•á...  \n",
       "3469  ‡§µ‡§∞‡§ø‡§∑‡•ç‡§† ‡§µ‡§ï‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§∂‡§æ‡§Ç‡§§ ‡§≠‡•Ç‡§∑‡§£ ‡§¨‡•ã‡§≤‡•á, ‡§Æ‡•á‡§∞‡•á ‡§ü‡•ç‡§µ‡•Ä‡§ü‡•ç‡§∏ ‡§ï‡§æ...  \n",
       "4487  ‡§Ø‡•á ‡§ê‡§∏‡§æ ‡§∏‡•á‡§≤‡•ç‡§´‡§º‡•Ä ‡§ï‡•à‡§Æ‡§∞‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§Æ‡•å‡§ú‡•Ç‡§¶ ‡§§‡•ã ‡§π‡•à, ‡§Æ‡§ó‡§∞ ‡§¶...  \n",
       "4005  ‡§ö‡•Ä‡§® ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§∞ ‡§ï‡§ø‡§Æ‡•Ä ‡§Ö‡§Ç‡§¶‡§∞ ‡§ò‡•Å‡§∏ ‡§ö‡•Å‡§ï‡•Ä ‡§π‡•à‡§Ç ‡§≠‡§æ‡§∞‡§§ ‡§ï‡•Ä ‡§∏‡•á‡§®...  \n",
       "3873  ‡§ß‡•Ç‡§≤ ‡§ö‡§ü‡§æ ‡§¶‡•ã ‡§ó‡§ø‡§¶‡•ç‡§ß‡•ã‡§Ç ‡§ï‡•ã ,‡§ú‡•ã ‡§ò‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Å‡§∏ ‡§ï‡§∞ ‡§ò‡§æ‡§§ ‡§ï‡§∞...  \n",
       "261   ‡§¨‡•à‡§Ç‡§ï‡§ø‡§ó ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§∏‡§Æ‡§Ø ‡§¨‡•à‡§Ç‡§ï‡•ã‡§Ç ‡§ï‡§æ ‡§ï‡•Å‡§≤ ‡§¨‡§ï‡§æ‡§Ø‡§æ ‡§ï...  \n",
       "1617    ‡§ú‡§Ø ‡§π‡§ø‡§®‡•ç‡§¶ ‡§ï‡•Ä ‡§∏‡•á‡§®‡§æ..     ‡§î‡§∞ ‡§ú‡•ã ‡§®‡§æ‡§≤‡§æ‡§Ø‡§ï ‡§¶‡•á‡§∂ ‡§¶‡•ç‡§∞‡•ã...  \n",
       "4728  ‡§Ø‡•á ‡§ï‡§æ‡§Ç‡§ó‡•ç‡§∞‡•á‡§∏ ‡§µ‡§æ‡§≤‡•á, ‡§Ö‡§ß‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§™‡§¶ ‡§µ‡§æ‡§≤‡§æ ‡§°‡•ç‡§∞‡§æ‡§Æ‡§æ ‡§∏‡§Æ‡§Ø  ...  \n",
       "2067                         ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•Ä ‡§è‡§ï ‡§î‡§∞ ‡§™‡§π‡§≤    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.261940Z",
     "iopub.status.busy": "2020-12-06T11:30:44.261774Z",
     "iopub.status.idle": "2020-12-06T11:30:44.265726Z",
     "shell.execute_reply": "2020-12-06T11:30:44.265318Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.261920Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_labels(label):\n",
    "    tmp = label.split(',')\n",
    "    ls = [0, 0, 0, 0]\n",
    "    if tmp[0] == 'non-hostile':\n",
    "        return ls\n",
    "    if 'fake' in tmp:\n",
    "        ls[0] = 1\n",
    "    if 'hate' in tmp:\n",
    "        ls[1] = 1\n",
    "    if 'offensive' in tmp:\n",
    "        ls[2] = 1\n",
    "    if 'defamation' in tmp:\n",
    "        ls[3] = 1\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.266578Z",
     "iopub.status.busy": "2020-12-06T11:30:44.266426Z",
     "iopub.status.idle": "2020-12-06T11:30:44.275241Z",
     "shell.execute_reply": "2020-12-06T11:30:44.274769Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.266559Z"
    }
   },
   "outputs": [],
   "source": [
    "train['encodelabels'] = train['task_1'].apply(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.277178Z",
     "iopub.status.busy": "2020-12-06T11:30:44.277024Z",
     "iopub.status.idle": "2020-12-06T11:30:44.332943Z",
     "shell.execute_reply": "2020-12-06T11:30:44.332475Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.277158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>task_1</th>\n",
       "      <th>full_tweet</th>\n",
       "      <th>tweet_raw_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>smiley</th>\n",
       "      <th>emoji</th>\n",
       "      <th>url</th>\n",
       "      <th>mentions</th>\n",
       "      <th>numerals</th>\n",
       "      <th>reserved_word</th>\n",
       "      <th>emotext</th>\n",
       "      <th>segmented_hash</th>\n",
       "      <th>clean</th>\n",
       "      <th>encodelabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>719</td>\n",
       "      <td>hate</td>\n",
       "      <td>@Sabir51861509 ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡•Ä ‡§π‡•à ‡§®‡•ç‡§Ø‡§æ...</td>\n",
       "      <td>‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡•Ä ‡§π‡•à ‡§®‡•ç‡§Ø‡§æ‡§Ø‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@Sabir51861509]</td>\n",
       "      <td>[10, 10, 90]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡•Ä ‡§π‡•à ‡§®‡•ç‡§Ø‡§æ‡§Ø‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§Ü‡§™‡§ï‡•á ...</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>1276</td>\n",
       "      <td>fake</td>\n",
       "      <td>15 ‡§ú‡•Ç‡§® ‡§ï‡•Ä ‡§∞‡§æ‡§§ ‡§ó‡§≤‡§µ‡§æ‡§® ‡§ò‡§æ‡§ü‡•Ä ‡§™‡§∞ ‡§π‡•Å‡§à ‡§â‡§∏ ‡§Æ‡•Å‡§†‡§≠‡•á‡•ú‡•§ ‡§§‡§ø‡§∞...</td>\n",
       "      <td>‡§ú‡•Ç‡§® ‡§ï‡•Ä ‡§∞‡§æ‡§§ ‡§ó‡§≤‡§µ‡§æ‡§® ‡§ò‡§æ‡§ü‡•Ä ‡§™‡§∞ ‡§π‡•Å‡§à ‡§â‡§∏ ‡§Æ‡•Å‡§†‡§≠‡•á‡•ú‡•§ ‡§§‡§ø‡§∞‡§Ç‡§ó‡•á...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[15]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>15 ‡§ú‡•Ç‡§® ‡§ï‡•Ä ‡§∞‡§æ‡§§ ‡§ó‡§≤‡§µ‡§æ‡§® ‡§ò‡§æ‡§ü‡•Ä ‡§™‡§∞ ‡§π‡•Å‡§à ‡§â‡§∏ ‡§Æ‡•Å‡§†‡§≠‡•á‡•ú‡•§ ‡§§‡§ø‡§∞...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>2748</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§™‡•Å‡§≤‡§ø‡§∏ ‡§ï‡§∏‡•ç‡§ü‡§°‡•Ä ‡§∏‡•á ‡§¨‡•Ä‡§è‡§ö‡§Ø‡•Ç ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡•á ‡§≤‡§æ‡§™‡§§‡§æ ‡§π‡•ã‡§®‡•á ...</td>\n",
       "      <td>‡§™‡•Å‡§≤‡§ø‡§∏ ‡§ï‡§∏‡•ç‡§ü‡§°‡•Ä ‡§∏‡•á ‡§¨‡•Ä‡§è‡§ö‡§Ø‡•Ç ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡•á ‡§≤‡§æ‡§™‡§§‡§æ ‡§π‡•ã‡§®‡•á ...</td>\n",
       "      <td>[#Allahabad]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/EpjUpwojjr]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[allahabad]</td>\n",
       "      <td>‡§™‡•Å‡§≤‡§ø‡§∏ ‡§ï‡§∏‡•ç‡§ü‡§°‡•Ä ‡§∏‡•á ‡§¨‡•Ä‡§è‡§ö‡§Ø‡•Ç ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡•á ‡§≤‡§æ‡§™‡§§‡§æ ‡§π‡•ã‡§®‡•á ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§¨‡§ß‡§æ‡§à ‡§π‡•ã ‡§Æ‡•ã‡§¶‡•Ä ‡§ú‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§® ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡•á 100 ‡§π‡§ú‡§º...</td>\n",
       "      <td>‡§¨‡§ß‡§æ‡§à ‡§π‡•ã ‡§Æ‡•ã‡§¶‡•Ä ‡§ú‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§® ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡•á ‡§π‡§ú‡§º‡§æ‡§∞ ‡§°...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[üòÇ]</td>\n",
       "      <td>[https://t.co/BUEX28Lfpe]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[100]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[face with tears of joy]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§¨‡§ß‡§æ‡§à ‡§π‡•ã ‡§Æ‡•ã‡§¶‡•Ä ‡§ú‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§® ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡•á 100 ‡§π‡§ú‡§º...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>2975</td>\n",
       "      <td>fake</td>\n",
       "      <td>‡§®‡•ã‡§µ‡§≤ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§∏‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ 20,000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∞‡•ã...</td>\n",
       "      <td>‡§®‡•ã‡§µ‡§≤ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§∏‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ 20 , 000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[20,000]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§®‡•ã‡§µ‡§≤ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§∏‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ 20,000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∞‡•ã...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>805</td>\n",
       "      <td>fake</td>\n",
       "      <td>‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∂‡•á‡§∑ ‡§¨‡§ö‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡•ã‡§à ‡§Æ...</td>\n",
       "      <td>‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∂‡•á‡§∑ ‡§¨‡§ö‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡•ã‡§à ‡§Æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∂‡•á‡§∑ ‡§¨‡§ö‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡•ã‡§à ‡§Æ...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>4150</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§∞‡•á‡§≤ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä @PiyushGoyal ‡§®‡•á ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§Æ‡•á‡§Ç #NEET_JEE...</td>\n",
       "      <td>‡§∞‡•á‡§≤ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡•á ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§Æ‡•á‡§Ç ‡§ï‡•Ä ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§¶‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§õ...</td>\n",
       "      <td>[#NEET_JEE]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/ly7wl5QP6l]</td>\n",
       "      <td>[@PiyushGoyal, @RailMinIndia]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[neet _ jee]</td>\n",
       "      <td>‡§∞‡•á‡§≤ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä   ‡§®‡•á ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§Æ‡•á‡§Ç   ‡§ï‡•Ä ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§¶‡•á‡§®‡•á ‡§µ‡§æ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>5209</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï‡•ã‡§π‡§≤‡•Ä ‡§ï‡•ã ‡§ü‡•Ä‡§Æ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú...</td>\n",
       "      <td>‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï‡•ã‡§π‡§≤‡•Ä ‡§ï‡•ã ‡§ü‡•Ä‡§Æ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú...</td>\n",
       "      <td>[#MSDhoni]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/6T2VP0pf7e]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ms dhoni]</td>\n",
       "      <td>‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï‡•ã‡§π‡§≤‡•Ä ‡§ï‡•ã ‡§ü‡•Ä‡§Æ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>3362</td>\n",
       "      <td>offensive</td>\n",
       "      <td>‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ú‡•ã ‡§®‡•Ä‡§Ç‡§µ ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§®‡•á ‡§∞‡§ñ‡•Ä ‡§π‡•à. ‡§Ø‡§ï‡•Ä‡§® ‡§∞‡§ñ...</td>\n",
       "      <td>‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ú‡•ã ‡§®‡•Ä‡§Ç‡§µ ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§®‡•á ‡§∞‡§ñ‡•Ä ‡§π‡•à. ‡§Ø‡§ï‡•Ä‡§® ‡§∞‡§ñ...</td>\n",
       "      <td>[#‡§∞‡§£_‡§Æ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[üö©, üö©]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[triangular flag, triangular flag]</td>\n",
       "      <td>[‡§∞‡§£ _‡§Æ]</td>\n",
       "      <td>‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ú‡•ã ‡§®‡•Ä‡§Ç‡§µ ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§®‡•á ‡§∞‡§ñ‡•Ä ‡§π‡•à. ‡§Ø‡§ï‡•Ä‡§® ‡§∞‡§ñ...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>2455</td>\n",
       "      <td>fake</td>\n",
       "      <td>‡§Ø‡§π ‡•ô‡§¨‡§∞ ‡§ú‡•ã ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ö‡§≤‡§æ‡§è‡§ó‡§æ ‡•§ ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§Æ...</td>\n",
       "      <td>‡§Ø‡§π ‡•ô‡§¨‡§∞ ‡§ú‡•ã ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ö‡§≤‡§æ‡§è‡§ó‡§æ ‡•§ ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§Æ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ø‡§π ‡•ô‡§¨‡§∞ ‡§ú‡•ã ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ö‡§≤‡§æ‡§è‡§ó‡§æ ‡•§ ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§Æ...</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>3330</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä: ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä ‡§®‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§∞‡§æ‡§∑...</td>\n",
       "      <td>‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä :  ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä ‡§®‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§∞...</td>\n",
       "      <td>[#PranabMukherjee]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/KFnDD9ZjmA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pranab mukherjee]</td>\n",
       "      <td>‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä: ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä ‡§®‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§∞‡§æ‡§∑...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>653</td>\n",
       "      <td>offensive</td>\n",
       "      <td>‡§ú‡§ø‡§®‡§ï‡§æ ‡§è‡§ï ‡§¨‡§æ‡§£ ‡§∏‡§Æ‡§Ç‡§¶‡§∞ ‡§§‡§ï ‡§ï‡•ã ‡§∏‡•ã‡§ñ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à,  ‡§Ö‡§Ø‡•ã‡§ß‡•ç‡§Ø‡§æ...</td>\n",
       "      <td>‡§ú‡§ø‡§®‡§ï‡§æ ‡§è‡§ï ‡§¨‡§æ‡§£ ‡§∏‡§Æ‡§Ç‡§¶‡§∞ ‡§§‡§ï ‡§ï‡•ã ‡§∏‡•ã‡§ñ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ,   ‡§Ö‡§Ø‡•ã‡§ß‡•ç...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[üî•, üö©]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fire, triangular flag]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§ú‡§ø‡§®‡§ï‡§æ ‡§è‡§ï ‡§¨‡§æ‡§£ ‡§∏‡§Æ‡§Ç‡§¶‡§∞ ‡§§‡§ï ‡§ï‡•ã ‡§∏‡•ã‡§ñ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à,  ‡§Ö‡§Ø‡•ã‡§ß‡•ç‡§Ø‡§æ...</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>3873</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä ‡§®‡§æ‡§∏‡§æ ‡§®‡•á ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•Ä ‡§ï...</td>\n",
       "      <td>‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä ‡§®‡§æ‡§∏‡§æ ‡§®‡•á ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•Ä ‡§ï...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/zUhyPfXZtV]</td>\n",
       "      <td>[@NASA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä ‡§®‡§æ‡§∏‡§æ ‡§®‡•á ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•Ä ‡§ï...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>1257</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>#WeatherUpdates : ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§∏‡§Æ‡•á‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§ï‡§à ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã...</td>\n",
       "      <td>:  ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§∏‡§Æ‡•á‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§ï‡§à ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§ó‡•Ä ‡§ù‡§Æ‡§æ‡§ù...</td>\n",
       "      <td>[#WeatherUpdates, #IMD, #WeatherForecast]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/pPO3WjiqKy]</td>\n",
       "      <td>[@IMDWeather]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[weather updates, imd, weather forecast]</td>\n",
       "      <td>: ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§∏‡§Æ‡•á‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§ï‡§à ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§ó‡•Ä ‡§ù‡§Æ‡§æ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unique ID</td>\n",
       "      <td>Labels Set</td>\n",
       "      <td>Post</td>\n",
       "      <td>Post</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Post</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>4267</td>\n",
       "      <td>hate,offensive</td>\n",
       "      <td>‡§Æ‡•Å‡§ó‡§≤‡•ã‡§Ç ‡§®‡•á ‡§∏‡§æ‡§Æ ‡§¶‡§æ‡§Æ ‡§¶‡§Ç‡§° ‡§≠‡•á‡§¶ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡§æ ‡§ß‡§∞...</td>\n",
       "      <td>‡§Æ‡•Å‡§ó‡§≤‡•ã‡§Ç ‡§®‡•á ‡§∏‡§æ‡§Æ ‡§¶‡§æ‡§Æ ‡§¶‡§Ç‡§° ‡§≠‡•á‡§¶ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡§æ ‡§ß‡§∞...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Æ‡•Å‡§ó‡§≤‡•ã‡§Ç ‡§®‡•á ‡§∏‡§æ‡§Æ ‡§¶‡§æ‡§Æ ‡§¶‡§Ç‡§° ‡§≠‡•á‡§¶ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡§æ ‡§ß‡§∞...</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>5497</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>#SushantSinghRajput ‡§ï‡•Ä ‡§ï‡•â‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§∏‡•á ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ...</td>\n",
       "      <td>‡§ï‡•Ä ‡§ï‡•â‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§∏‡•á ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ‡§π‡•à ‡§ï‡§ø ‡§µ‡•á ‡§Ö‡§™‡§®‡•á ‡§™‡§ø‡§§‡§æ ‡§ï...</td>\n",
       "      <td>[#SushantSinghRajput]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/yaJg6GQCCW]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sushant singh rajput]</td>\n",
       "      <td>‡§ï‡•Ä ‡§ï‡•â‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§∏‡•á ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ‡§π‡•à ‡§ï‡§ø ‡§µ‡•á ‡§Ö‡§™‡§®‡•á ‡§™‡§ø‡§§‡§æ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>583</td>\n",
       "      <td>non-hostile</td>\n",
       "      <td>‡§Ö‡§∏‡§≤‡•Ä ‡§π‡•Ä‡§∞‡•ã ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç  ‡§∏‡•Å‡§®‡§ø‡§è \"‡§§‡•á‡§∞‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ...</td>\n",
       "      <td>‡§Ö‡§∏‡§≤‡•Ä ‡§π‡•Ä‡§∞‡•ã ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç  ‡§∏‡•Å‡§®‡§ø‡§è \"‡§§‡•á‡§∞‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/69wERP7uQl]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ö‡§∏‡§≤‡•Ä ‡§π‡•Ä‡§∞‡•ã ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç  ‡§∏‡•Å‡§®‡§ø‡§è \"‡§§‡•á‡§∞‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ...</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>2678</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@sambitswaraj ‡§Ø‡•á ‡§∏‡§¨ ‡§∏‡§æ‡§≤‡•á ‡§ó‡§≤‡•Ä ‡§ï‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á  ‡§∏‡•á ‡§≠‡•Ä ...</td>\n",
       "      <td>‡§Ø‡•á ‡§∏‡§¨ ‡§∏‡§æ‡§≤‡•á ‡§ó‡§≤‡•Ä ‡§ï‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á  ‡§∏‡•á ‡§≠‡•Ä ‡§¨‡•á‡§ï‡§æ‡§∞ ‡§π‡•à‡•§</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[@sambitswaraj]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>‡§Ø‡•á ‡§∏‡§¨ ‡§∏‡§æ‡§≤‡•á ‡§ó‡§≤‡•Ä ‡§ï‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á  ‡§∏‡•á ‡§≠‡•Ä ‡§¨‡•á‡§ï‡§æ‡§∞ ‡§π‡•à‡•§</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>873</td>\n",
       "      <td>defamation</td>\n",
       "      <td>#‡§π‡•Ä‡§∞‡§ñ‡§æ‡§® ‡§â‡§∞‡•ç‡§´‡§º ‡§™‡§∞‡•Ä ‡§ñ‡§æ‡§® ‡§ï‡•ã ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä Arrest  ‡§ï‡§∞‡•á‡§Ç ...</td>\n",
       "      <td>#‡§π‡•Ä‡§∞‡§ñ‡§æ‡§® ‡§â‡§∞‡•ç‡§´‡§º ‡§™‡§∞‡•Ä ‡§ñ‡§æ‡§® ‡§ï‡•ã ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä Arrest  ‡§ï‡§∞‡•á‡§Ç ...</td>\n",
       "      <td>[#‡§π, #Just‡§∏, #Arrestheerkhan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[‡§π, just‡§∏, arrestheerkhan]</td>\n",
       "      <td>‡•Ä‡§∞‡§ñ‡§æ‡§® ‡§â‡§∞‡•ç‡§´‡§º ‡§™‡§∞‡•Ä ‡§ñ‡§æ‡§® ‡§ï‡•ã ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä Arrest  ‡§ï‡§∞‡•á‡§Ç ‡§ï...</td>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id          task_1  \\\n",
       "719         719            hate   \n",
       "1209       1276            fake   \n",
       "2633       2748     non-hostile   \n",
       "43           43     non-hostile   \n",
       "2860       2975            fake   \n",
       "805         805            fake   \n",
       "4035       4150     non-hostile   \n",
       "5008       5209     non-hostile   \n",
       "3247       3362       offensive   \n",
       "2340       2455            fake   \n",
       "3215       3330     non-hostile   \n",
       "653         653       offensive   \n",
       "3758       3873     non-hostile   \n",
       "1190       1257     non-hostile   \n",
       "0     Unique ID      Labels Set   \n",
       "4152       4267  hate,offensive   \n",
       "5296       5497     non-hostile   \n",
       "583         583     non-hostile   \n",
       "2563       2678       offensive   \n",
       "873         873      defamation   \n",
       "\n",
       "                                             full_tweet  \\\n",
       "719   @Sabir51861509 ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡•Ä ‡§π‡•à ‡§®‡•ç‡§Ø‡§æ...   \n",
       "1209  15 ‡§ú‡•Ç‡§® ‡§ï‡•Ä ‡§∞‡§æ‡§§ ‡§ó‡§≤‡§µ‡§æ‡§® ‡§ò‡§æ‡§ü‡•Ä ‡§™‡§∞ ‡§π‡•Å‡§à ‡§â‡§∏ ‡§Æ‡•Å‡§†‡§≠‡•á‡•ú‡•§ ‡§§‡§ø‡§∞...   \n",
       "2633  ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§ï‡§∏‡•ç‡§ü‡§°‡•Ä ‡§∏‡•á ‡§¨‡•Ä‡§è‡§ö‡§Ø‡•Ç ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡•á ‡§≤‡§æ‡§™‡§§‡§æ ‡§π‡•ã‡§®‡•á ...   \n",
       "43    ‡§¨‡§ß‡§æ‡§à ‡§π‡•ã ‡§Æ‡•ã‡§¶‡•Ä ‡§ú‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§® ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡•á 100 ‡§π‡§ú‡§º...   \n",
       "2860  ‡§®‡•ã‡§µ‡§≤ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§∏‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ 20,000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∞‡•ã...   \n",
       "805   ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∂‡•á‡§∑ ‡§¨‡§ö‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡•ã‡§à ‡§Æ...   \n",
       "4035  ‡§∞‡•á‡§≤ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä @PiyushGoyal ‡§®‡•á ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§Æ‡•á‡§Ç #NEET_JEE...   \n",
       "5008  ‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï‡•ã‡§π‡§≤‡•Ä ‡§ï‡•ã ‡§ü‡•Ä‡§Æ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú...   \n",
       "3247  ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ú‡•ã ‡§®‡•Ä‡§Ç‡§µ ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§®‡•á ‡§∞‡§ñ‡•Ä ‡§π‡•à. ‡§Ø‡§ï‡•Ä‡§® ‡§∞‡§ñ...   \n",
       "2340  ‡§Ø‡§π ‡•ô‡§¨‡§∞ ‡§ú‡•ã ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ö‡§≤‡§æ‡§è‡§ó‡§æ ‡•§ ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§Æ...   \n",
       "3215  ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä: ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä ‡§®‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§∞‡§æ‡§∑...   \n",
       "653   ‡§ú‡§ø‡§®‡§ï‡§æ ‡§è‡§ï ‡§¨‡§æ‡§£ ‡§∏‡§Æ‡§Ç‡§¶‡§∞ ‡§§‡§ï ‡§ï‡•ã ‡§∏‡•ã‡§ñ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à,  ‡§Ö‡§Ø‡•ã‡§ß‡•ç‡§Ø‡§æ...   \n",
       "3758  ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä ‡§®‡§æ‡§∏‡§æ ‡§®‡•á ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•Ä ‡§ï...   \n",
       "1190  #WeatherUpdates : ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§∏‡§Æ‡•á‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§ï‡§à ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã...   \n",
       "0                                                  Post   \n",
       "4152  ‡§Æ‡•Å‡§ó‡§≤‡•ã‡§Ç ‡§®‡•á ‡§∏‡§æ‡§Æ ‡§¶‡§æ‡§Æ ‡§¶‡§Ç‡§° ‡§≠‡•á‡§¶ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡§æ ‡§ß‡§∞...   \n",
       "5296  #SushantSinghRajput ‡§ï‡•Ä ‡§ï‡•â‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§∏‡•á ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ...   \n",
       "583   ‡§Ö‡§∏‡§≤‡•Ä ‡§π‡•Ä‡§∞‡•ã ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç  ‡§∏‡•Å‡§®‡§ø‡§è \"‡§§‡•á‡§∞‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ...   \n",
       "2563  @sambitswaraj ‡§Ø‡•á ‡§∏‡§¨ ‡§∏‡§æ‡§≤‡•á ‡§ó‡§≤‡•Ä ‡§ï‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á  ‡§∏‡•á ‡§≠‡•Ä ...   \n",
       "873   #‡§π‡•Ä‡§∞‡§ñ‡§æ‡§® ‡§â‡§∞‡•ç‡§´‡§º ‡§™‡§∞‡•Ä ‡§ñ‡§æ‡§® ‡§ï‡•ã ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä Arrest  ‡§ï‡§∞‡•á‡§Ç ...   \n",
       "\n",
       "                                         tweet_raw_text  \\\n",
       "719   ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡•Ä ‡§π‡•à ‡§®‡•ç‡§Ø‡§æ‡§Ø‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø...   \n",
       "1209  ‡§ú‡•Ç‡§® ‡§ï‡•Ä ‡§∞‡§æ‡§§ ‡§ó‡§≤‡§µ‡§æ‡§® ‡§ò‡§æ‡§ü‡•Ä ‡§™‡§∞ ‡§π‡•Å‡§à ‡§â‡§∏ ‡§Æ‡•Å‡§†‡§≠‡•á‡•ú‡•§ ‡§§‡§ø‡§∞‡§Ç‡§ó‡•á...   \n",
       "2633  ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§ï‡§∏‡•ç‡§ü‡§°‡•Ä ‡§∏‡•á ‡§¨‡•Ä‡§è‡§ö‡§Ø‡•Ç ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡•á ‡§≤‡§æ‡§™‡§§‡§æ ‡§π‡•ã‡§®‡•á ...   \n",
       "43    ‡§¨‡§ß‡§æ‡§à ‡§π‡•ã ‡§Æ‡•ã‡§¶‡•Ä ‡§ú‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§® ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡•á ‡§π‡§ú‡§º‡§æ‡§∞ ‡§°...   \n",
       "2860  ‡§®‡•ã‡§µ‡§≤ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§∏‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ 20 , 000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ...   \n",
       "805   ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∂‡•á‡§∑ ‡§¨‡§ö‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡•ã‡§à ‡§Æ...   \n",
       "4035  ‡§∞‡•á‡§≤ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡•á ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§Æ‡•á‡§Ç ‡§ï‡•Ä ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§¶‡•á‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§õ...   \n",
       "5008  ‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï‡•ã‡§π‡§≤‡•Ä ‡§ï‡•ã ‡§ü‡•Ä‡§Æ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú...   \n",
       "3247  ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ú‡•ã ‡§®‡•Ä‡§Ç‡§µ ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§®‡•á ‡§∞‡§ñ‡•Ä ‡§π‡•à. ‡§Ø‡§ï‡•Ä‡§® ‡§∞‡§ñ...   \n",
       "2340  ‡§Ø‡§π ‡•ô‡§¨‡§∞ ‡§ú‡•ã ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ö‡§≤‡§æ‡§è‡§ó‡§æ ‡•§ ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§Æ...   \n",
       "3215  ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä :  ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä ‡§®‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§∞...   \n",
       "653   ‡§ú‡§ø‡§®‡§ï‡§æ ‡§è‡§ï ‡§¨‡§æ‡§£ ‡§∏‡§Æ‡§Ç‡§¶‡§∞ ‡§§‡§ï ‡§ï‡•ã ‡§∏‡•ã‡§ñ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à ,   ‡§Ö‡§Ø‡•ã‡§ß‡•ç...   \n",
       "3758  ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä ‡§®‡§æ‡§∏‡§æ ‡§®‡•á ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•Ä ‡§ï...   \n",
       "1190  :  ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§∏‡§Æ‡•á‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§ï‡§à ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§ó‡•Ä ‡§ù‡§Æ‡§æ‡§ù...   \n",
       "0                                                  Post   \n",
       "4152  ‡§Æ‡•Å‡§ó‡§≤‡•ã‡§Ç ‡§®‡•á ‡§∏‡§æ‡§Æ ‡§¶‡§æ‡§Æ ‡§¶‡§Ç‡§° ‡§≠‡•á‡§¶ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡§æ ‡§ß‡§∞...   \n",
       "5296  ‡§ï‡•Ä ‡§ï‡•â‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§∏‡•á ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ‡§π‡•à ‡§ï‡§ø ‡§µ‡•á ‡§Ö‡§™‡§®‡•á ‡§™‡§ø‡§§‡§æ ‡§ï...   \n",
       "583   ‡§Ö‡§∏‡§≤‡•Ä ‡§π‡•Ä‡§∞‡•ã ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç  ‡§∏‡•Å‡§®‡§ø‡§è \"‡§§‡•á‡§∞‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ...   \n",
       "2563          ‡§Ø‡•á ‡§∏‡§¨ ‡§∏‡§æ‡§≤‡•á ‡§ó‡§≤‡•Ä ‡§ï‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á  ‡§∏‡•á ‡§≠‡•Ä ‡§¨‡•á‡§ï‡§æ‡§∞ ‡§π‡•à‡•§   \n",
       "873   #‡§π‡•Ä‡§∞‡§ñ‡§æ‡§® ‡§â‡§∞‡•ç‡§´‡§º ‡§™‡§∞‡•Ä ‡§ñ‡§æ‡§® ‡§ï‡•ã ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä Arrest  ‡§ï‡§∞‡•á‡§Ç ...   \n",
       "\n",
       "                                       hashtags smiley   emoji  \\\n",
       "719                                          []     []      []   \n",
       "1209                                         []     []      []   \n",
       "2633                               [#Allahabad]     []      []   \n",
       "43                                           []     []     [üòÇ]   \n",
       "2860                                         []     []      []   \n",
       "805                                          []     []      []   \n",
       "4035                                [#NEET_JEE]     []      []   \n",
       "5008                                 [#MSDhoni]     []      []   \n",
       "3247                                    [#‡§∞‡§£_‡§Æ]     []  [üö©, üö©]   \n",
       "2340                                         []     []      []   \n",
       "3215                         [#PranabMukherjee]     []      []   \n",
       "653                                          []     []  [üî•, üö©]   \n",
       "3758                                         []     []      []   \n",
       "1190  [#WeatherUpdates, #IMD, #WeatherForecast]     []      []   \n",
       "0                                            []     []      []   \n",
       "4152                                         []     []      []   \n",
       "5296                      [#SushantSinghRajput]     []      []   \n",
       "583                                          []     []      []   \n",
       "2563                                         []     []      []   \n",
       "873               [#‡§π, #Just‡§∏, #Arrestheerkhan]     []      []   \n",
       "\n",
       "                            url                       mentions      numerals  \\\n",
       "719                          []               [@Sabir51861509]  [10, 10, 90]   \n",
       "1209                         []                             []          [15]   \n",
       "2633  [https://t.co/EpjUpwojjr]                             []            []   \n",
       "43    [https://t.co/BUEX28Lfpe]                             []         [100]   \n",
       "2860                         []                             []      [20,000]   \n",
       "805                          []                             []            []   \n",
       "4035  [https://t.co/ly7wl5QP6l]  [@PiyushGoyal, @RailMinIndia]            []   \n",
       "5008  [https://t.co/6T2VP0pf7e]                             []            []   \n",
       "3247                         []                             []            []   \n",
       "2340                         []                             []            []   \n",
       "3215  [https://t.co/KFnDD9ZjmA]                             []          [10]   \n",
       "653                          []                             []            []   \n",
       "3758  [https://t.co/zUhyPfXZtV]                        [@NASA]            []   \n",
       "1190  [https://t.co/pPO3WjiqKy]                  [@IMDWeather]            []   \n",
       "0                            []                             []            []   \n",
       "4152                         []                             []            []   \n",
       "5296  [https://t.co/yaJg6GQCCW]                             []            []   \n",
       "583   [https://t.co/69wERP7uQl]                             []            []   \n",
       "2563                         []                [@sambitswaraj]            []   \n",
       "873                          []                             []            []   \n",
       "\n",
       "     reserved_word                             emotext  \\\n",
       "719             []                                  []   \n",
       "1209            []                                  []   \n",
       "2633            []                                  []   \n",
       "43              []            [face with tears of joy]   \n",
       "2860            []                                  []   \n",
       "805             []                                  []   \n",
       "4035            []                                  []   \n",
       "5008            []                                  []   \n",
       "3247            []  [triangular flag, triangular flag]   \n",
       "2340            []                                  []   \n",
       "3215            []                                  []   \n",
       "653             []             [fire, triangular flag]   \n",
       "3758            []                                  []   \n",
       "1190            []                                  []   \n",
       "0               []                                  []   \n",
       "4152            []                                  []   \n",
       "5296            []                                  []   \n",
       "583             []                                  []   \n",
       "2563            []                                  []   \n",
       "873             []                                  []   \n",
       "\n",
       "                                segmented_hash  \\\n",
       "719                                         []   \n",
       "1209                                        []   \n",
       "2633                               [allahabad]   \n",
       "43                                          []   \n",
       "2860                                        []   \n",
       "805                                         []   \n",
       "4035                              [neet _ jee]   \n",
       "5008                                [ms dhoni]   \n",
       "3247                                   [‡§∞‡§£ _‡§Æ]   \n",
       "2340                                        []   \n",
       "3215                        [pranab mukherjee]   \n",
       "653                                         []   \n",
       "3758                                        []   \n",
       "1190  [weather updates, imd, weather forecast]   \n",
       "0                                           []   \n",
       "4152                                        []   \n",
       "5296                    [sushant singh rajput]   \n",
       "583                                         []   \n",
       "2563                                        []   \n",
       "873                 [‡§π, just‡§∏, arrestheerkhan]   \n",
       "\n",
       "                                                  clean  encodelabels  \n",
       "719     ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§¨‡§®‡•Ä ‡§π‡•à ‡§®‡•ç‡§Ø‡§æ‡§Ø‡§™‡§æ‡§≤‡§ø‡§ï‡§æ ‡§Ü‡§™‡§ï‡•á ...  [0, 1, 0, 0]  \n",
       "1209  15 ‡§ú‡•Ç‡§® ‡§ï‡•Ä ‡§∞‡§æ‡§§ ‡§ó‡§≤‡§µ‡§æ‡§® ‡§ò‡§æ‡§ü‡•Ä ‡§™‡§∞ ‡§π‡•Å‡§à ‡§â‡§∏ ‡§Æ‡•Å‡§†‡§≠‡•á‡•ú‡•§ ‡§§‡§ø‡§∞...  [1, 0, 0, 0]  \n",
       "2633  ‡§™‡•Å‡§≤‡§ø‡§∏ ‡§ï‡§∏‡•ç‡§ü‡§°‡•Ä ‡§∏‡•á ‡§¨‡•Ä‡§è‡§ö‡§Ø‡•Ç ‡§ï‡•á ‡§õ‡§æ‡§§‡•ç‡§∞ ‡§ï‡•á ‡§≤‡§æ‡§™‡§§‡§æ ‡§π‡•ã‡§®‡•á ...  [0, 0, 0, 0]  \n",
       "43    ‡§¨‡§ß‡§æ‡§à ‡§π‡•ã ‡§Æ‡•ã‡§¶‡•Ä ‡§ú‡•Ä ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§® ‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§ï‡•ã ‡§™‡•Ç‡§∞‡•á 100 ‡§π‡§ú‡§º...  [0, 0, 0, 0]  \n",
       "2860  ‡§®‡•ã‡§µ‡§≤ ‡§ï‡•ã‡§∞‡•ã‡§®‡§æ‡§µ‡§æ‡§Ø‡§∞‡§∏ ‡§∏‡•á ‡§∏‡§Ç‡§ï‡•ç‡§∞‡§Æ‡§ø‡§§ 20,000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∞‡•ã...  [1, 0, 0, 0]  \n",
       "805   ‡§™‡§æ‡§ï‡§ø‡§∏‡•ç‡§§‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∂‡•á‡§∑ ‡§¨‡§ö‡•á ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡•ã‡§à ‡§Æ...  [1, 0, 0, 0]  \n",
       "4035  ‡§∞‡•á‡§≤ ‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä   ‡§®‡•á ‡§Æ‡•Å‡§Ç‡§¨‡§à ‡§Æ‡•á‡§Ç   ‡§ï‡•Ä ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§¶‡•á‡§®‡•á ‡§µ‡§æ...  [0, 0, 0, 0]  \n",
       "5008  ‡§µ‡§ø‡§∞‡§æ‡§ü ‡§ï‡•ã‡§π‡§≤‡•Ä ‡§ï‡•ã ‡§ü‡•Ä‡§Æ ‡§á‡§Ç‡§°‡§ø‡§Ø‡§æ ‡§∏‡•á ‡§¨‡§æ‡§π‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú...  [0, 0, 0, 0]  \n",
       "3247  ‡§π‡§ø‡§®‡•ç‡§¶‡•Å‡§§‡•ç‡§µ ‡§ï‡•Ä ‡§ú‡•ã ‡§®‡•Ä‡§Ç‡§µ ‡§Æ‡•ã‡§¶‡•Ä‡§ú‡•Ä ‡§®‡•á ‡§∞‡§ñ‡•Ä ‡§π‡•à. ‡§Ø‡§ï‡•Ä‡§® ‡§∞‡§ñ...  [0, 0, 1, 0]  \n",
       "2340  ‡§Ø‡§π ‡•ô‡§¨‡§∞ ‡§ú‡•ã ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•Ä‡§°‡§ø‡§Ø‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ö‡§≤‡§æ‡§è‡§ó‡§æ ‡•§ ‡§¶‡§ï‡•ç‡§∑‡§ø‡§£ ‡§Ö‡§Æ...  [1, 0, 0, 0]  \n",
       "3215  ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä: ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§®‡§∞‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§Æ‡•ã‡§¶‡•Ä ‡§®‡•á ‡§™‡•Ç‡§∞‡•ç‡§µ ‡§∞‡§æ‡§∑...  [0, 0, 0, 0]  \n",
       "653   ‡§ú‡§ø‡§®‡§ï‡§æ ‡§è‡§ï ‡§¨‡§æ‡§£ ‡§∏‡§Æ‡§Ç‡§¶‡§∞ ‡§§‡§ï ‡§ï‡•ã ‡§∏‡•ã‡§ñ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à,  ‡§Ö‡§Ø‡•ã‡§ß‡•ç‡§Ø‡§æ...  [0, 0, 1, 0]  \n",
       "3758  ‡§Ö‡§Æ‡•á‡§∞‡§ø‡§ï‡•Ä ‡§Ö‡§Ç‡§§‡§∞‡§ø‡§ï‡•ç‡§∑ ‡§è‡§ú‡•á‡§Ç‡§∏‡•Ä ‡§®‡§æ‡§∏‡§æ ‡§®‡•á ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§æ‡§Ç‡§° ‡§ï‡•Ä ‡§ï...  [0, 0, 0, 0]  \n",
       "1190    : ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä ‡§∏‡§Æ‡•á‡§§ ‡§¶‡•á‡§∂ ‡§ï‡•á ‡§ï‡§à ‡§π‡§ø‡§∏‡•ç‡§∏‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§π‡•ã‡§ó‡•Ä ‡§ù‡§Æ‡§æ...  [0, 0, 0, 0]  \n",
       "0                                                  Post  [0, 0, 0, 0]  \n",
       "4152  ‡§Æ‡•Å‡§ó‡§≤‡•ã‡§Ç ‡§®‡•á ‡§∏‡§æ‡§Æ ‡§¶‡§æ‡§Æ ‡§¶‡§Ç‡§° ‡§≠‡•á‡§¶ ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§π‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡§æ ‡§ß‡§∞...  [0, 1, 1, 0]  \n",
       "5296    ‡§ï‡•Ä ‡§ï‡•â‡§≤ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§° ‡§∏‡•á ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ‡§π‡•à ‡§ï‡§ø ‡§µ‡•á ‡§Ö‡§™‡§®‡•á ‡§™‡§ø‡§§‡§æ...  [0, 0, 0, 0]  \n",
       "583   ‡§Ö‡§∏‡§≤‡•Ä ‡§π‡•Ä‡§∞‡•ã ‡§ï‡•Ä ‡§Ü‡§µ‡§æ‡§ú ‡§Æ‡•á‡§Ç  ‡§∏‡•Å‡§®‡§ø‡§è \"‡§§‡•á‡§∞‡•Ä ‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§Æ‡•á‡§Ç ...  [0, 0, 0, 0]  \n",
       "2563          ‡§Ø‡•á ‡§∏‡§¨ ‡§∏‡§æ‡§≤‡•á ‡§ó‡§≤‡•Ä ‡§ï‡•á ‡§ï‡•Å‡§§‡•ç‡§§‡•á  ‡§∏‡•á ‡§≠‡•Ä ‡§¨‡•á‡§ï‡§æ‡§∞ ‡§π‡•à‡•§  [0, 0, 1, 0]  \n",
       "873    ‡•Ä‡§∞‡§ñ‡§æ‡§® ‡§â‡§∞‡•ç‡§´‡§º ‡§™‡§∞‡•Ä ‡§ñ‡§æ‡§® ‡§ï‡•ã ‡§ú‡§≤‡•ç‡§¶ ‡§π‡•Ä Arrest  ‡§ï‡§∞‡•á‡§Ç ‡§ï...  [0, 0, 0, 1]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.334313Z",
     "iopub.status.busy": "2020-12-06T11:30:44.334154Z",
     "iopub.status.idle": "2020-12-06T11:30:44.338478Z",
     "shell.execute_reply": "2020-12-06T11:30:44.337925Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.334292Z"
    }
   },
   "outputs": [],
   "source": [
    "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    acc_list = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        set_true = set( np.where(y_true[i])[0] )\n",
    "        set_pred = set( np.where(y_pred[i])[0] )\n",
    "        tmp_a = None\n",
    "        if len(set_true) == 0 and len(set_pred) == 0:\n",
    "            tmp_a = 1\n",
    "        else:\n",
    "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
    "                    float( len(set_true.union(set_pred)) )\n",
    "        acc_list.append(tmp_a)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.339483Z",
     "iopub.status.busy": "2020-12-06T11:30:44.339254Z",
     "iopub.status.idle": "2020-12-06T11:30:44.343877Z",
     "shell.execute_reply": "2020-12-06T11:30:44.343407Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.339462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sections of config\n",
    "\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.344735Z",
     "iopub.status.busy": "2020-12-06T11:30:44.344587Z",
     "iopub.status.idle": "2020-12-06T11:30:44.352206Z",
     "shell.execute_reply": "2020-12-06T11:30:44.351794Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.344715Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiLabelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.clean\n",
    "        self.targets = self.data.encodelabels\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.353037Z",
     "iopub.status.busy": "2020-12-06T11:30:44.352888Z",
     "iopub.status.idle": "2020-12-06T11:30:44.362946Z",
     "shell.execute_reply": "2020-12-06T11:30:44.362524Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.353017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (5528, 15)\n",
      "TRAIN Dataset: (4422, 15)\n",
      "TEST Dataset: (1106, 15)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_data=train.sample(frac=train_size,random_state=200)\n",
    "test_data=train.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
    "\n",
    "training_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)\n",
    "testing_set = MultiLabelDataset(test_data, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.363814Z",
     "iopub.status.busy": "2020-12-06T11:30:44.363663Z",
     "iopub.status.idle": "2020-12-06T11:30:44.366642Z",
     "shell.execute_reply": "2020-12-06T11:30:44.366231Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.363795Z"
    }
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:44.367516Z",
     "iopub.status.busy": "2020-12-06T11:30:44.367362Z",
     "iopub.status.idle": "2020-12-06T11:30:50.464232Z",
     "shell.execute_reply": "2020-12-06T11:30:50.463695Z",
     "shell.execute_reply.started": "2020-12-06T11:30:44.367496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0, inplace=False)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(models[model_num])\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.465407Z",
     "iopub.status.busy": "2020-12-06T11:30:50.465243Z",
     "iopub.status.idle": "2020-12-06T11:30:50.468241Z",
     "shell.execute_reply": "2020-12-06T11:30:50.467768Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.465385Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.469100Z",
     "iopub.status.busy": "2020-12-06T11:30:50.468949Z",
     "iopub.status.idle": "2020-12-06T11:30:50.474819Z",
     "shell.execute_reply": "2020-12-06T11:30:50.474359Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.469080Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.475733Z",
     "iopub.status.busy": "2020-12-06T11:30:50.475583Z",
     "iopub.status.idle": "2020-12-06T11:30:50.489087Z",
     "shell.execute_reply": "2020-12-06T11:30:50.488688Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.475714Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "#         if _%50==0:\n",
    "#             print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    final_outputs = np.array(fin_outputs) >=0.5\n",
    "    final = []\n",
    "    final_t = []\n",
    "    final_fine = [[],[],[],[]]\n",
    "    final_fine_t = [[],[],[],[]]\n",
    "    for (i,j) in zip(final_outputs, fin_targets):\n",
    "        output_sum = sum(i)\n",
    "        target_sum = sum(j)\n",
    "        if output_sum == 0:\n",
    "            final.append(0)\n",
    "        else:\n",
    "            final.append(1)\n",
    "        if target_sum == 0:\n",
    "            final_t.append(0)\n",
    "        else:\n",
    "            final_t.append(1)\n",
    "        for p in range(4):\n",
    "            final_fine[p].append(int(i[p]))\n",
    "            final_fine_t[p].append(int(j[p]))\n",
    "    print(\"Coarse:\")\n",
    "    print(classification_report(final, final_t))\n",
    "    for i in range(4):\n",
    "        print(\"Fine\", i)\n",
    "        print(classification_report(final_fine[i], final_fine_t[i]))\n",
    "#     return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:30:50.489932Z",
     "iopub.status.busy": "2020-12-06T11:30:50.489775Z",
     "iopub.status.idle": "2020-12-06T11:37:02.339961Z",
     "shell.execute_reply": "2020-12-06T11:37:02.339449Z",
     "shell.execute_reply.started": "2020-12-06T11:30:50.489913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/tathagata.raha/miniconda3/envs/fastai/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1764: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "139it [00:32,  4.24it/s]\n",
      "2it [00:00, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3369062840938568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.96it/s]\n",
      "/home/tathagata.raha/miniconda3/envs/fastai/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.70      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53      1106\n",
      "   macro avg       0.50      0.27      0.35      1106\n",
      "weighted avg       1.00      0.53      0.70      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80      1106\n",
      "   macro avg       0.50      0.40      0.44      1106\n",
      "weighted avg       1.00      0.80      0.89      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.93      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:33,  4.18it/s]\n",
      "2it [00:00, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.4448566436767578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.75it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.70      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53      1106\n",
      "   macro avg       0.50      0.27      0.35      1106\n",
      "weighted avg       1.00      0.53      0.70      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80      1106\n",
      "   macro avg       0.50      0.40      0.44      1106\n",
      "weighted avg       1.00      0.80      0.89      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.93      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:33,  4.13it/s]\n",
      "2it [00:00, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.5884934067726135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.70it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.55      0.71      1068\n",
      "           1       0.07      0.89      0.12        38\n",
      "\n",
      "    accuracy                           0.56      1106\n",
      "   macro avg       0.53      0.72      0.41      1106\n",
      "weighted avg       0.96      0.56      0.69      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90      1068\n",
      "           1       0.14      0.82      0.24        38\n",
      "\n",
      "    accuracy                           0.82      1106\n",
      "   macro avg       0.57      0.82      0.57      1106\n",
      "weighted avg       0.96      0.82      0.88      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.93      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.50      0.44      0.47      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:33,  4.10it/s]\n",
      "2it [00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.414557546377182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.65it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.61      0.75       935\n",
      "           1       0.29      0.89      0.44       171\n",
      "\n",
      "    accuracy                           0.65      1106\n",
      "   macro avg       0.63      0.75      0.60      1106\n",
      "weighted avg       0.86      0.65      0.70      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92       967\n",
      "           1       0.48      0.77      0.59       139\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.72      0.83      0.76      1106\n",
      "weighted avg       0.90      0.87      0.88      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      1075\n",
      "           1       0.11      0.48      0.18        31\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.55      0.68      0.55      1106\n",
      "weighted avg       0.96      0.87      0.91      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94      1103\n",
      "           1       0.02      1.00      0.04         3\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.51      0.94      0.49      1106\n",
      "weighted avg       1.00      0.88      0.94      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.09it/s]\n",
      "2it [00:00, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.08098824322223663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.61it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.65      0.78       873\n",
      "           1       0.41      0.91      0.57       233\n",
      "\n",
      "    accuracy                           0.71      1106\n",
      "   macro avg       0.69      0.78      0.67      1106\n",
      "weighted avg       0.85      0.71      0.73      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       939\n",
      "           1       0.54      0.71      0.61       167\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.74      0.80      0.76      1106\n",
      "weighted avg       0.88      0.86      0.87      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.93      1048\n",
      "           1       0.17      0.41      0.24        58\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.57      0.65      0.59      1106\n",
      "weighted avg       0.92      0.87      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      1066\n",
      "           1       0.18      0.60      0.28        40\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.58      0.75      0.61      1106\n",
      "weighted avg       0.95      0.89      0.92      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.07it/s]\n",
      "2it [00:00, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.08873924612998962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.55it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77       703\n",
      "           1       0.61      0.78      0.68       403\n",
      "\n",
      "    accuracy                           0.74      1106\n",
      "   macro avg       0.73      0.75      0.73      1106\n",
      "weighted avg       0.76      0.74      0.74      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       785\n",
      "           1       0.80      0.55      0.66       321\n",
      "\n",
      "    accuracy                           0.83      1106\n",
      "   macro avg       0.82      0.75      0.77      1106\n",
      "weighted avg       0.83      0.83      0.82      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1044\n",
      "           1       0.22      0.50      0.31        62\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.60      0.70      0.62      1106\n",
      "weighted avg       0.93      0.88      0.90      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      1054\n",
      "           1       0.21      0.54      0.31        52\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.59      0.72      0.62      1106\n",
      "weighted avg       0.94      0.89      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.06it/s]\n",
      "2it [00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.299334853887558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.57it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84       731\n",
      "           1       0.66      0.91      0.77       375\n",
      "\n",
      "    accuracy                           0.81      1106\n",
      "   macro avg       0.80      0.83      0.80      1106\n",
      "weighted avg       0.85      0.81      0.82      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       891\n",
      "           1       0.65      0.67      0.66       215\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.78      0.79      0.79      1106\n",
      "weighted avg       0.87      0.87      0.87      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       959\n",
      "           1       0.46      0.43      0.44       147\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.68      0.68      0.68      1106\n",
      "weighted avg       0.85      0.86      0.85      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1011\n",
      "           1       0.40      0.55      0.46        95\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.68      0.73      0.70      1106\n",
      "weighted avg       0.91      0.89      0.90      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.07it/s]\n",
      "2it [00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.11874614655971527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.58it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.80       729\n",
      "           1       0.61      0.84      0.71       377\n",
      "\n",
      "    accuracy                           0.76      1106\n",
      "   macro avg       0.75      0.78      0.75      1106\n",
      "weighted avg       0.80      0.76      0.77      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90       853\n",
      "           1       0.69      0.61      0.65       253\n",
      "\n",
      "    accuracy                           0.85      1106\n",
      "   macro avg       0.79      0.76      0.78      1106\n",
      "weighted avg       0.84      0.85      0.85      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      1028\n",
      "           1       0.26      0.46      0.33        78\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.61      0.68      0.63      1106\n",
      "weighted avg       0.91      0.87      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94      1028\n",
      "           1       0.35      0.59      0.44        78\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.66      0.75      0.69      1106\n",
      "weighted avg       0.92      0.89      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.07it/s]\n",
      "2it [00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss:  0.006169774569571018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.59it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.71      0.81       797\n",
      "           1       0.55      0.91      0.68       309\n",
      "\n",
      "    accuracy                           0.76      1106\n",
      "   macro avg       0.75      0.81      0.75      1106\n",
      "weighted avg       0.84      0.76      0.78      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       933\n",
      "           1       0.53      0.68      0.59       173\n",
      "\n",
      "    accuracy                           0.85      1106\n",
      "   macro avg       0.73      0.78      0.75      1106\n",
      "weighted avg       0.87      0.85      0.86      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      1002\n",
      "           1       0.35      0.46      0.40       104\n",
      "\n",
      "    accuracy                           0.87      1106\n",
      "   macro avg       0.64      0.69      0.66      1106\n",
      "weighted avg       0.89      0.87      0.88      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1036\n",
      "           1       0.31      0.59      0.41        70\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.64      0.75      0.67      1106\n",
      "weighted avg       0.93      0.89      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95      1106\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.50      0.45      0.47      1106\n",
      "weighted avg       1.00      0.90      0.95      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [00:34,  4.06it/s]\n",
      "2it [00:00, 10.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss:  0.09804540127515793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.82       739\n",
      "           1       0.63      0.89      0.74       367\n",
      "\n",
      "    accuracy                           0.79      1106\n",
      "   macro avg       0.78      0.81      0.78      1106\n",
      "weighted avg       0.83      0.79      0.80      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       895\n",
      "           1       0.62      0.65      0.63       211\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.77      0.78      0.77      1106\n",
      "weighted avg       0.86      0.86      0.86      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1012\n",
      "           1       0.34      0.50      0.41        94\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.65      0.71      0.67      1106\n",
      "weighted avg       0.90      0.88      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1008\n",
      "           1       0.45      0.60      0.52        98\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.71      0.77      0.73      1106\n",
      "weighted avg       0.91      0.90      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.94      1102\n",
      "           1       0.01      0.25      0.02         4\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.50      0.57      0.48      1106\n",
      "weighted avg       0.99      0.89      0.94      1106\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:02.341202Z",
     "iopub.status.busy": "2020-12-06T11:37:02.341039Z",
     "iopub.status.idle": "2020-12-06T11:37:02.346303Z",
     "shell.execute_reply": "2020-12-06T11:37:02.345781Z",
     "shell.execute_reply.started": "2020-12-06T11:37:02.341180Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:02.347177Z",
     "iopub.status.busy": "2020-12-06T11:37:02.347040Z",
     "iopub.status.idle": "2020-12-06T11:37:05.661360Z",
     "shell.execute_reply": "2020-12-06T11:37:05.660891Z",
     "shell.execute_reply.started": "2020-12-06T11:37:02.347159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:03, 10.59it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs, targets = validation(testing_loader)\n",
    "\n",
    "final_outputs = np.array(outputs) >=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:05.662164Z",
     "iopub.status.busy": "2020-12-06T11:37:05.662027Z",
     "iopub.status.idle": "2020-12-06T11:37:05.674775Z",
     "shell.execute_reply": "2020-12-06T11:37:05.674307Z",
     "shell.execute_reply.started": "2020-12-06T11:37:05.662146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Score = 0.6835443037974683\n",
      "Hamming Loss = 0.11867088607594936\n"
     ]
    }
   ],
   "source": [
    "val_hamming_loss = metrics.hamming_loss(targets, final_outputs)\n",
    "val_hamming_score = hamming_score(np.array(targets), np.array(final_outputs))\n",
    "\n",
    "print(f\"Hamming Score = {val_hamming_score}\")\n",
    "print(f\"Hamming Loss = {val_hamming_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:05.675675Z",
     "iopub.status.busy": "2020-12-06T11:37:05.675502Z",
     "iopub.status.idle": "2020-12-06T11:37:05.715583Z",
     "shell.execute_reply": "2020-12-06T11:37:05.715090Z",
     "shell.execute_reply.started": "2020-12-06T11:37:05.675645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.82       739\n",
      "           1       0.63      0.89      0.74       367\n",
      "\n",
      "    accuracy                           0.79      1106\n",
      "   macro avg       0.78      0.81      0.78      1106\n",
      "weighted avg       0.83      0.79      0.80      1106\n",
      "\n",
      "Fine 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       895\n",
      "           1       0.62      0.65      0.63       211\n",
      "\n",
      "    accuracy                           0.86      1106\n",
      "   macro avg       0.77      0.78      0.77      1106\n",
      "weighted avg       0.86      0.86      0.86      1106\n",
      "\n",
      "Fine 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1012\n",
      "           1       0.34      0.50      0.41        94\n",
      "\n",
      "    accuracy                           0.88      1106\n",
      "   macro avg       0.65      0.71      0.67      1106\n",
      "weighted avg       0.90      0.88      0.89      1106\n",
      "\n",
      "Fine 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      1008\n",
      "           1       0.45      0.60      0.52        98\n",
      "\n",
      "    accuracy                           0.90      1106\n",
      "   macro avg       0.71      0.77      0.73      1106\n",
      "weighted avg       0.91      0.90      0.91      1106\n",
      "\n",
      "Fine 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.94      1102\n",
      "           1       0.01      0.25      0.02         4\n",
      "\n",
      "    accuracy                           0.89      1106\n",
      "   macro avg       0.50      0.57      0.48      1106\n",
      "weighted avg       0.99      0.89      0.94      1106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "total = len(targets)\n",
    "final = []\n",
    "final_t = []\n",
    "final_fine = [[],[],[],[]]\n",
    "final_fine_t = [[],[],[],[]]\n",
    "for (i,j) in zip(final_outputs, targets):\n",
    "    output_sum = sum(i)\n",
    "    target_sum = sum(j)\n",
    "    if output_sum == 0:\n",
    "        final.append(0)\n",
    "    else:\n",
    "        final.append(1)\n",
    "    if target_sum == 0:\n",
    "        final_t.append(0)\n",
    "    else:\n",
    "        final_t.append(1)\n",
    "    for p in range(4):\n",
    "        final_fine[p].append(int(i[p]))\n",
    "        final_fine_t[p].append(int(j[p]))\n",
    "print(\"Coarse:\")\n",
    "print(classification_report(final, final_t))\n",
    "for i in range(4):\n",
    "    print(\"Fine\", i)\n",
    "    print(classification_report(final_fine[i], final_fine_t[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-06T11:37:05.716445Z",
     "iopub.status.busy": "2020-12-06T11:37:05.716301Z",
     "iopub.status.idle": "2020-12-06T11:37:06.515742Z",
     "shell.execute_reply": "2020-12-06T11:37:06.515034Z",
     "shell.execute_reply.started": "2020-12-06T11:37:05.716427Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f5a253470e04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-06T11:37:06.516304Z",
     "iopub.status.idle": "2020-12-06T11:37:06.516589Z"
    }
   },
   "outputs": [],
   "source": [
    "final_fine = [[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-12-06T11:37:06.517208Z",
     "iopub.status.idle": "2020-12-06T11:37:06.517499Z"
    }
   },
   "outputs": [],
   "source": [
    "final_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
